---
title: "South Fork McKenzie River Pedigree Project Analysis Notebook"
output:
  html_document:
    df_print: paged
    code_folding: hide
    toc: true
    toc_float: true
    toc_collapsed: false
---

```{r, message = FALSE, warning=FALSE}
require(RLDNe)
require(car)
require(DHARMa)
require(emmeans)
require(MASS)
require(effects)
require(glmmTMB)
require(lme4)
require(kableExtra)
require(gt)
require(gtsummary)
require(tidyverse)
require(magrittr)
require(countreg)
require(lmerTest)
require(lubridate)
require(khroma)
```


# Summary

This notebook contains a log of all analyses for the 2022 South Fork McKenzie River spring Chinook salmon genetic pedigree study. Inference of the pedigree used here is conducted in a separate notebook titled "parentage_notebook" in this same repository.

This is an R notebook. The .html version of this file is a fully rendered and interactive log. To view it, save the html and open in a browse. The .rmd version can be opened within R studio. To reproduce results or edit the analysis: clone the full repository onto your local machine and open the r project in rstudio. This will provide all needed data and objects.

# Pedigrees and Cohort Rationale

This notebook relies on a pedigree of all Chinook Salmon released above Cougar Dam on the South Fork McKenzie River from 2007 - 2017 using potential offspring sampled from 2010 to 2020.

## Summary of Cohort Years

Previous reports and manuscripts evaluating the reintroduction of Chinook salmon above Cougar Dam on the South Fork McKenzie river have considered NOR salmon sampled from 2010 to 2015 as potential offspring of salmon released above Cougar Dam from 2007 - 2012. 

Most Chinook salmon on the South Fork McKenzie express an age at maturity of 3 - 6 years. Therefore, previous reports (relying on 2010 - 2015 NOR returns) have inferred a pedigree for salmon released above the dam from 2007 - 2009. Results based on the pedigree of salmon released above Cougar Dam in 2010 were also provided along with the caveat that age 6 offspring were not yet evaluated and some results such as Total Lifetime Fitness and Cohort Replacement Rate were likely underestimates.

Continuing this work, we have since genotyped NOR salmon sampled on the South Fork McKenzie from 2016 to 2020, as well as salmon released above Cougar dam from 2013 to 2017. These new data allow us to complete the pedigree of salmon released above Cougar Dam in 2010, infer full pedigrees TLF  for salmon released above Cougar Dam from 2011 - 2014, and partial pedigrees for salmon released above the dam from 2015 - 2017.

## Inferring Pedigrees Again

Irrevocable updates to software packages used to assign parentage (COLONY) prevent us from exactly reproducing the approach used to infer the pedigrees used in previous reports. We chose to infer all pedigrees from parent years 2007 to 2017 (offspring year 2010 - 2020) from the raw genetic data using a consistent approach rather than simply combining previous pedigrees with those inferred from new data.  

This means that parent year results from 2007-2010 and offspring year results from 2010 - 2015, that have previously been reported on may change. In the parentage assignment notebook we evaluated how much changes to the parentage assignment approach affected assignment rate, cohort replacement rate. The overall assignment rate differed an average of 1.6% across the six years where pedigrees were previously inferred.

This approach has several advantages:  
(1) Trends - Results based on the pedigrees such as Cohort Replacement Rate and Total Lifetime Fitness suffer from the same biases across all years, allowing more confidence in the identification of year - year trends.   
(2) Fitness modeling - Similar to above, applying a consistent approach to pedigree inference gives us more power to identify predictors of fitness by allowing us to combine data from more years into a single analysis  
(3) Grandparentage and Great-Grandparentage: If a unified filtering and pedigree inference approach is used for the entire dataset, we can more confidently combine pedigrees inferred for a single offspring year with one another, allowing for a 3 (or perhaps even 4) generation pedigree. This means we can identify gradnparentage and great grandparentage, opening up the potential to address many important questions such as fitness effects of hatchery selection.  
(4) Minor Issues - In reproducing previous results, minor errors in code were identified. While these errors ultimately are expected to have little effect on the final pedigrees and results, inferring the pedigrees again allows us to fix these small errors and evaluate their effects. For example in the Cervus pedigrees, the software is run using a single parent year and a single offspring year, then the results are concatenated for all parent years within an offspring year. This renders the likelihoods incomparable. Likelihoods are used to break ties when inferring the cervus pedigree, but it likely never had a large effect because Colony is given priority in the consensus pedigree. 

Throughout the notebook we present the results for all parent years using the newly inferred pedigrees.

# Goals 

(1) Summarise dataset and release history  
(2) Summarise assignment of offspring to parents, use to infer age structure.      
(3) Estimate total lifetime fitness (TLF) for parent cohorts  
(4) Estimate cohort replacement rates for parent cohorts  
(5) Assess variables that influence fitness with general linear models  
(6) Estimate effective number of breeders using NeEstimator  
(7) Compare HOR and NOR fitness

This is an R notebook. The .html version of this file is a fully rendered and interactive log. To view it, save the html and open in a browse. The .rmd version can be opened within R studio. To reproduce results or edit the analysis: clone the full repository onto tyour local machine and open the r project in rstudio. This will provide all needed data and objects. 

# Data

__Genotype and Metadata__  
A log of the work to consolidate sample metadata can be found in the _cougar_trap_metadata_mgmt_ and the _meta_data_consolidation_ R notebooks in the metadata directory of this repository. There are also readmes in that directory that explain subdirectory structure and files. 

The log (R notebook) for genotype data prep is titled _genotype_data_prep_ and can be found in the genotypes directory of this repository.

Here, we import the final outputs of this notebook containing both sample metadata and genotype which include (by R environment name):

(1) __full_unfilt:__ All genotypes and metadata, no genotype quality filtering. Includes all individuals known to be potential parents or offspring for the project.
(2) __full_data_1.0:__ Genotypes and metadata, after removing individuals with fewer than 7 scored genotypes and removing duplicates. 

```{r}
load("../genotypes/genotype_data/full_unfiltered_dataset.R")
load("../genotypes/genotype_data/full_filtered_dataset.R")
```


Both files also contain some individuals twice (for example: Cougar trap LSDR samples have two rows, one for each observation at the Cougar Trap). So, let's also produce some objects that only include the final observations for individuals.

(3) __dedup_unfilt:__ same as full_unfilt above, but only last observation of an individual retained.     
(4) __dedup:__ same as full_data_1.0 above, but only second observation of an individual retained.     

```{r}
dedup <- full_data_1.0 %>%
  group_by(sample_id) %>%
  slice_max(date, with_ties = FALSE) %>%
  ungroup()

dedup_unfilt <- full_unfilt %>%
  group_by(sample_id) %>%
  slice_max(date, with_ties = FALSE) %>%
  ungroup()
```


__Pedigree__

The log for inferring final consensus pedigree can be found in the _parentage_notebook_ in the parentage directory of this repository. It includes parentages for all potential offspring sampled from 2010 - 2020.

Here we import the final consensus pedigree. Note that this pedigree only has rows for assigned parentages, offspring with no parentage assigned do not appear in this object.

```{r}
load("../parentage/pedigree.R")
```

# Dataset and Release Summary Counts

Let's summarise the complete dataset, by source and origin, without respect to where the fish wound up.
```{r}
kable(dedup %>% count(year, type, origin, section) %>% 
  pivot_wider(id_cols = year, names_from = c(type, origin, section), values_from = n, names_sep = "\n"), caption = "Table N0: sample sizes by source", align = "c") %>%
  kable_classic(full_width = T, html_font = "Arial" )
  
  
```
__Table N0:__ Sample sizes after filtering by year, origin and source. Source column names refer to three values, separated by spaces: (1) where was the sample originally encountered (hatchery, cougar trap, during a spawning ground survey, or as a precocial male), (2) origin, and (3) for SGS samples only, was the SGS conducted above or below Cougar Dam

## Parents

### Counts and Sex Ratios

Throughout this report (and previous reports), it has been useful to split the dataset up and present results by offspring and candidate parents. Let's keep with this approach and present the numbers of potential parents (__table N1__) and the numbers of potential offspring __table N7__ .

Here we only present the numbers for final filtered dataset for two reasons:  

(1) In later analyses where we calculate demographic parameters such as CRR, we define the number of candidate parents as the number of potential parents passed to Colony or Cervus, to which we assign potential offspring. Keeping this consistent will make these tables less confusing down the road.   
(2) Duplicates: There are many individuals filtered from the raw dataset because they have identical genotypes to another sample. This is potentially due to tissue samples being stored in a shared container (one fin clip gets split into multiple pieces), or spawning ground surveys sampling the same individual that was already sampled at the Cougar Trap. Including these individuals in the number of parents is misleading.  


```{r}
#unfilt_parent_summary <- dedup_unfilt %>%
#  filter(cand_parent == TRUE) %>%
#  count(year, type, origin) %>%
#  rename(n_unfiltered = n)

# let's add a column for sex ratio

filt_parent_summary <- dedup %>%
  filter(cand_parent == TRUE) %>%
  count(year, type, origin) %>%
  rename(n_final = n)

filt_parent_summary %<>%
  unite("type_origin", type, origin) %>%
  pivot_wider(id_cols = year, names_from = type_origin, values_from = n_final)

options(knitr.kable.NA = '')
kable(filt_parent_summary, caption = "Table N1: Number of Candidate Parents") %>%
  kable_classic(full_width = T, html_font = "Arial" )
# there are two 
```

__Table N1:__ Number of individuals relased above Cougar dam retained in the final filtered dataset. These values correspond to candidate parents used in the assignments. "Hatchery Outplant HOR" refers to individuals trapped at either McKenzie or Leaburg hatchery and released above the dam, all are HOR. Cougar Trap includes both NOR, HOR and unknown origin (NA) individuals released above the dam. Precocial males refers to a small set of jacks sampled on the spawning grounds above the dam in 2014. SGS refers to additional individuals sampled during spawning ground surveys above the dam.  


Let's also split up the parent cohorts by sex. Here we split into different tables to make them more manageable.

```{r}
kable(dedup %>%
  filter( cand_parent == TRUE, year < 2018) %>%
  count(year, sex) %>%
  pivot_wider(id_cols = year, names_from = sex, values_from = n) %>%
  mutate(sex_ratio = M/`F`), caption = "Table N2: Sex Ratios of all Candidate Parents", align = "c", digits = 2 ) %>%
  kable_classic(full_width = F, html_font = "Arial")
```
__Table N2:__ Number of candidate parents females (F) and males (M) (individual released above Cougar Dam and retained in the final dataset). Here we split by source, individuals are either from Cougar Trap (NOR and HOR) or from the hatchery (HOR). Sex ratio is presented as n_male/n_female.

```{r}
kable(dedup %>%
  filter(type == "hatchery_outplant", cand_parent == TRUE) %>%
  count(year, sex) %>%
  pivot_wider(id_cols = year, names_from = sex, values_from = n) %>%
  mutate(sex_ratio = M/`F`), caption = "Table N3: Sex Ratios of Candidate Parents from Hatchery", align = "c", digits = 2) %>%
  kable_classic(full_width = F, html_font = "Arial"  )

kable(dedup %>%
  filter(type == "cougar_trap", cand_parent == TRUE, year < 2018) %>%
  count(year, sex) %>%
  pivot_wider(id_cols = year, names_from = sex, values_from = n) %>%
  mutate(sex_ratio = M/`F`), caption = "Table N4: Sex Ratios of Candidate Parents from Cougar Trap", align = "c", digits = 2) %>%
  kable_classic(full_width = F, html_font = "Arial"  )

```
__Tables N3 - N4:__ Number of candidate parents females (F) and males (M) (individual released above Cougar Dam and retained in the final dataset). Here we split by source, individuals are either from Cougar Trap (NOR and HOR) or from the hatchery (HOR). Sex ratio is presented as n_male/n_female.

### Cougar Trap LSDR / Recycling

Finally, let's summarise the approaches used for releasing individuals from the Cougar Trap. 

Some terms to define:  
(1) __Late-season downstream release (LSDR):__ Individuals that arrive at the Cougar Trap on and after September 1st are double floy tagged and released downstream at Forest Glen. If they return to the trap a second time, they are released above the dam.  
(2) __Recycling__: All individuals at the Cougar Trap, regardless of date, are first released downstream of the dam (either in Forest Glen, or just the dam tailrace). If they return a secodn time they are released above the dam.

__LDSR / Recycling Summary__
During 2010, 2011 and 2012, neither LSDR or recycling was used. All fish that were trapped and survived were released above the dam.   
During 2013 and 2014, the LSDR approach was applied to NOR fish after September 1st. Some HORs on and after September 1st were also LSDR but not all.   
From 2015 onwards all NOR are recycled. Some HOR are also recycled, but most are not.

Let's collect some numbers here. 

```{r}

kable(full_data_1.0 %>%
  filter(type == "cougar_trap", origin == "NOR", year %in% c(2013, 2014)) %>%
    filter(date %within% interval(ymd("2013-09-01"), ymd("2013-12-01")) |  date %within% interval(ymd("2014-09-01"), ymd("2014-12-01"))) %>%
  count(year, recapture) %>%
  pivot_wider(id_cols = year, names_from = recapture, values_from = n) %>%
  mutate("percent recaptured" = (RE/NEW)*100) %>%
  rename("n new" = NEW, "n recaptured" = RE)  , digits = 1, caption = "Table N5: LSDR Program Summary", align = "c") %>%
  kable_classic(full_width = F, html_font = "Arial" )
```
__Table N5__: LSDR summary: Number of NOR fish sampled at Cougar trap on or after September 1st (n new), and the number of these fish that returned a second time.  
_note: Banks 2016 tech report states that 74 (not 75 as presented here) NOR fish returned on or after September 1st in 2014. I went back to Nick's data to make sure I didn't mess something up. His data also has 75, not 74 individuals. The discrepancy stems from a single individual in 2014 with only 7 loci scored. This individual is in Nick's raw data, but not in the pedigree file used to calculate these numbers in the report, due to missingness. Here we apply a different filtering approach (details in genotype data prep), so the individual is retained._   


```{r}

kable(full_data_1.0 %>%
  filter(type == "cougar_trap", origin == "NOR", year > 2014) %>%
    group_by(sample_id) %>% # a couple individuals are recorded three times, this will break these counts, just get the first two instances
    slice_max(date, n = 2, with_ties = FALSE) %>%
    ungroup() %>%
  count(year, recapture) %>%
  pivot_wider(id_cols = year, names_from = recapture, values_from = n) %>%
  select(-`NA`) %>% # one NA individual with no metadata
  mutate("percent recaptured" = (RE/NEW)*100) %>%
  rename("n new" = NEW, "n recaptured" = RE)  , digits = 1, caption = "Table N6: Recycling Program Summary", align = "c") %>%
  kable_classic(full_width = F, html_font = "Arial" )
  
  
```
__Table N6__: Recycling Summary: Number of NOR fish sampled at Cougar trap, and the number of these fish that returned a second time.

## Offspring

Now let's summarise the potential offspring. Once again we present the counts from the final filtered dataset, because these are the values we use to calculate demographic results such as CRR, and there may be duplicates in the unfiltered dataset due to batch sampling or carcass sampling.

```{r}
kable(dedup %>%
  filter(origin == "NOR") %>%
  count(year, type) %>%
  pivot_wider(id_cols = year, names_from = type, values_from = n), caption = "Table N7: Potential Offspring Counts") %>%
  kable_classic(full_width = F, html_font = "Arial" )
```
__Table N7:__ Number of potential offspring (NOR individuals after filtering), sampled at the Cougar Trap, during spawning ground surveys, or as precocial males observed on spawning grounds above the dam. Note that spawning ground survey counts include individuals from surveys above the dam as well (1 in 2014 and 4 in 2016)

# Assignments

Here we summarise assignment of offspring to parents, infer age structure and evaluate the efficacy of LSDR and recycling programs at excluding NOR immigrants from above the dam. 

For summarizing assignments we'll start simply, then get more complex.

## Assignments, by Offpsring Year

We'll start simply. How many offspring in a given year assign to parents above the dam

```{r}
# let's get the metadata on the pedigree
pedigree_meta <- dedup %>%
  select(sample_id, year, type, date) %>%
  rename_with(.fn = ~ paste0("offspring_", .x)) %>%
  right_join(pedigree, by = c("offspring_sample_id" = "offspring_sample_id"))

#father
pedigree_meta <- dedup %>%
  select(sample_id, year, type, date) %>%
  rename_with(.fn = ~ paste0("father_", .x)) %>%
  right_join(pedigree_meta, by = c("father_sample_id" = "father")) %>%
  rename(father = father_sample_id)

#mother
pedigree_meta <- dedup %>%
  select(sample_id, year, type, date) %>%
  rename_with(.fn = ~ paste0("mother_", .x)) %>%
  right_join(pedigree_meta, by = c("mother_sample_id" = "mother")) %>%
  rename(mother = mother_sample_id)

pedigree_meta %<>%
  mutate(parent_year = (coalesce(father_year, mother_year)))
```

```{r, message = FALSE, warning=FALSE}
kable(pedigree_meta %>%
  group_by(offspring_year) %>%
  summarise(n = n(), assigned_n = n() - sum(mother == "none" & father == "none", na.rm = TRUE), assn_rate = (n()-sum(mother == "none" & father == "none", na.rm = TRUE))/n()) %>%
  mutate(assignment_percentage = assn_rate*100) %>%
  select(offspring_year,n_offspring = n, n_assigned = assigned_n, assignment_percentage), digits = 1, caption = "Table N8: Assignment rates per year") %>%
kable_classic(full_width = F, html_font = "Arial" )

```
__Table N8:__ Number of potential offspring that assign to parents above the dam. Potential offspring are defined as any individual sampled (below dam, at Cougar Trap, or above dam), that are NOR.  

People may be interested in just how many individuals show up at the trap, not ALL potential offspring, this will also be useful for comparing our assignmetn rates with the previously published ones (which don't include carcass samples). We will consider this in greater detail in the section [Recycling], but let's make revised table split by source.


```{r}
kable(pedigree_meta %>%
  group_by(offspring_year) %>%
    filter(offspring_type == "cougar_trap") %>%
  summarise(n = n(), assigned_n = n() - sum(mother == "none" & father == "none", na.rm = TRUE), assn_rate = (n()-sum(mother == "none" & father == "none", na.rm = TRUE))/n()) %>%
  mutate(assignment_percentage = assn_rate*100) %>%
  select(offspring_year,n_offspring = n, n_assigned = assigned_n, assignment_percentage), digits = 1, caption = "Table N8: Assignment rates per year, Cougar Only") %>%
kable_classic(full_width = F, html_font = "Arial" )

```
__Table N8b:__ Number of potential offspring sampled intially at Cougar Trap that assign to parents above the dam. Potential offspring are defined as any individual sampled (below dam, at Cougar Trap, or above dam), that are NOR.  

__NOTE BUG__ My values are a little different here than when I calculated similar ones in the parentage notebook. I msitakenly included to the precocial males in the parentage notebook. After removing these, the mean absolute difference in assignment rates is even smaller (0.7% vs 1.5%). 

```{r, eval = FALSE}
#getting that mean differnce in assignment rates number
(0.063-(13/221)+0.388-(136/357)+0.652-(320/500)+0.686-(151/223)+.613-(117/191)+.73-(173/240))/6
```


## AAM: Assignments, by Offspring Year and Parent Year

Here we get more complex and split the assignment summaries according to parent year. This allows us evaluate age at maturity (AAM) and split each offspring year into age classes.

First a table with everything.

```{r, message = FALSE, warning=FALSE}
kable(pedigree_meta %>%
  filter(!(is.na(parent_year))) %>% # exclude non-assigments
  mutate(age = as.numeric(offspring_year) - as.numeric(parent_year)) %>%
  group_by(offspring_year, age) %>%
  summarise(n = n()) %>%
  mutate(percent = 100*(n/sum(n))), digits = 0, caption = "Table N9: Age Structure, by Offspring Year") %>%
  kable_classic(full_width = F, html_font = "Arial") %>%
  kable_styling(fixed_thead = T) %>%
  scroll_box(height = "400px")
  
  
```
__Table N9:__ Age of offspring in each offspring year. 

Let's also present this as a figure. 

```{r}
aam_data <- pedigree_meta %>%
  mutate(parent_year = (coalesce(father_year, mother_year))) %>%
  filter(!(is.na(parent_year))) %>%
  mutate(age = as.numeric(offspring_year) - as.numeric(parent_year)) %>%
  mutate(age = as.factor(age), offspring_year = as.factor(offspring_year)) 


ggplot(data = aam_data) + 
  geom_bar(aes(offspring_year, fill = age), position = position_dodge(preserve = 'single'))+scale_fill_viridis_d(name = "Age")+scale_color_viridis_d(name = "Age")+theme_bw()+xlab("Offspring Year")+scale_x_discrete(labels = c("2010*", "2011*", "2012*", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020"))
```
  
__Figure N1__ Number of age 3, 4, 5 and 6 individuals in each offspring year.  
_* note earliest parent year in dataset is 2007, so only offpsring years from 2013 and later could possibly have all offspring ages_

__Averages__  
Finally let's produce a summary table of age structure, averaged across all years where we can assign ages for all offspring (2013 - 2020). This will come in handy later.

```{r}
kable(aam_data %>%
  filter(!(offspring_year %in% c("2010" ,"2011", "2012"))) %>%
  count(age) %>%
  summarise(age = age, n = n, proportion = n / sum(n)), caption = "Table N10: Mean Age Structure", align = "c", digits = 3,) %>%
kable_classic(full_width = F, html_font = "Arial" )
```
__Table N10:__ Mean age structure of returning NOR offspring from 2013-2020. This includes all years we have the data to assign to parents in 3, 4, 5, and 6 years prior.  

Age 6 offspring compose just ~2% of TLF, but age 5 offspring compose 42%. So we can probably comfortably use our dataset to describe TLF for 2007 - 2015 parent years. Fitness of parents in our pedigree (up to 2020 offspring year) is likely to strongly underestimate 2016 and 2017 TLF.

## Assignments, by Offspring Year and Parent Type/Year

Here we summarise assignment of offspring to different parent types and year. 

Each below table represents a single pair of offspring and parent years. The type of offspring is listed in the first column and the results are split between parent types along the remaining columns (e.g. same format as table 3 from NSNT report)

When the "type" of parent varies between two parents, the female parent type is listed first.  For example, if an offspring is assigned to a reintroduced mother and carcass father, the column would be called "reintro/carcass."

Note that some tables are missing e.g. 2017 offspring assigned to 2011 parents. This is because there are no such assignments in the pedigree, or only a single assigment.



```{r}
# the format of the table in the report is difficult to produce in r
# let's not change the format of the table, instead we'll write some helper functions for filling it out 

#let's add a column for the type of assignment, and one for combined types
pedigree_meta %<>%
  mutate(assn_type = case_when((mother == "none" & father == "none") ~ "none",
                               (mother == "none" & father != "none") ~ "male_only",
                               (mother != "none" & father == "none") ~ "female_only",
                               (mother != "none" & father != "none") ~ "pair",)) %>%
  mutate(parent_type = case_when((father_type == mother_type) ~ father_type,
                                 (is.na(father_type) & !(is.na(mother_type))) ~ mother_type,
                                  (is.na(mother_type) & !(is.na(father_type))) ~ father_type,
                                   (father_type != mother_type) ~ paste(mother_type, father_type, sep = "/")))

# function
t4_helper <- function(p_year, off_year){pedigree_meta %>%
  filter(offspring_year == off_year) %>%
  filter(parent_year == p_year) %>%
  mutate(parent_type = as.factor(parent_type)) %>%
  select(offspring_type, parent_type, assn_type) %>%
  tbl_strata(
    strata = parent_type,
    .tbl_fun = ~ .x %>%
      tbl_summary( by = assn_type, percent = NULL)
  ) %>%
  modify_caption(paste(paste("parent year: ", p_year), paste("offspring year: ", off_year), sep = "  ,")) %>%
  as_kable_extra() %>%
  kable_classic(full_width = F, html_font = "Arial")
}
```
Note that we're only presenting these tables for the new offspring years.

```{r, cache = TRUE}
#t4 helper function example

t4_helper("2010", "2016")
t4_helper("2011", "2016")
t4_helper("2012", "2016")
t4_helper("2013", "2016")

# t4_helper("2011", "2017") none so this breaks
t4_helper("2012", "2017")
t4_helper("2013", "2017")
# t4_helper("2014", "2017") only one so this breaks

t4_helper("2012", "2018")
t4_helper("2013", "2018")
t4_helper("2014", "2018")
t4_helper("2015", "2018")

t4_helper("2013", "2019")
t4_helper("2014", "2019")
t4_helper("2015", "2019")
t4_helper("2016", "2019")

# t4_helper("2014", "2020") none so this breaks
t4_helper("2015", "2020")
t4_helper("2016", "2020")
# t4_helper("2017", "2020") none so this breaks
```

## Recycling

In this section we make the assumption that offspring that do not assign to any candidate parent are not offspring of salmon above the dam, and are instead NOR immigrants (i.e. strays) from the mainstem of SFMK below dam populations. 

Under this assumption we can evaluate the efficacy of the recycling or LSDR approach at excluding NOR immigrants from being released above the dam. We exclude offspring year 2010 - 2012, since we do not have all of the potential parents from these offspring years included as candidate parents in our parentage analysis.

### GLM

If we think about this for a while the essential question being asked is:

>On a given day, what is the probability that an NOR individual that arrives at the Cougar trap is not assigned to a parent above the dam?  

We term this probability "probability of immigrant". We can model "probability of immigrant" as the response variable in a binomial GLM, using the explanatory variable julian date, and (optionally) including random effect of year. We are also interested in the effect of sex here. It is covariate that we expect will reduce overdispersion in the model fit because we expect the relationship between straying and date to depend on sex.

We could get a lot more detailed with our modeling here, but let's attempt to model probability of immigrant as a function of julian day and sex. 

First let's plot make some simple plots.

```{r, warning=FALSE, message=FALSE}
strays <- pedigree_meta %>% 
  filter(offspring_year > 2012, offspring_type == "cougar_trap") %>%
  left_join(select(dedup, sample_id, sex), by = c("offspring_sample_id" = "sample_id")) %>%
  mutate(immigrant = case_when(assn_type == "none" ~ "immigrant",
                               TRUE ~ "return"),
         immigrant_i = case_when(assn_type == "none" ~ 1,
                               TRUE ~ 0),
         jday = yday(ymd(offspring_date)))

ggplot(strays, aes(jday, immigrant_i))+geom_count(alpha = 0.5)+geom_smooth(method = "glm", method.args=list(family="binomial"))+theme_classic()+xlab("Julian Day")+ylab("Immigrant\n1 = immigrant 0 = return")+scale_color_viridis_d()+geom_vline(aes(xintercept = 245), linetype = "dashed", color  = "red")
```

__Figure N2:__ Julian day vs immigrant count at Cougar Trap. An offspring with no assigned parentage is considered an immigrant (scored as 1), an offpsring with at least one parent is considered a return (scored as zero). Circle size corresponds to number of individuals that day. Offspring years from 2013-2020 are considered. Smoothing curve is a simple binomial glm on the immigrant variable using only the effect of Julian day. Julian day 245 is on or one day from the September 1st cutoff used for LSDR. It is displayed as vertical dashed red line.

Here we see there is a clear relationship between the propensity for an individual to be assigned a parent from above the dam and the day it is sampled at the Cougar Trap. 

We also know that the overall assignemnt rate varies from year to year. Let's see if the relationship between Julian day and the propensity for an immigrant to be sampled at the Cougar trap depends on year.

```{r, warning=FALSE, message=FALSE}
ggplot(strays, aes(jday, immigrant_i, color = as.factor(offspring_year)))+geom_count(alpha = 0.5)+geom_smooth(method = "glm", method.args=list(family="binomial"))+theme_classic()+xlab("Julian Day")+ylab("Immigrant?\n1 = immigrant \n 0 = return")+scale_color_viridis_d(name = "Offspring Year")+geom_vline(aes(xintercept = 245), linetype = "dashed", color  = "red")
```

__Figure N3:__ Julian day vs immigrant count at Cougar Trap, by offspring year. An offspring with no assigned parentage is considered an immigrant (scored as 1), an offpsring with at least one parent is considered a return (scored as zero). Circle size corresponds to number of individuals that day. Offspring years from 2013-2020 are considered. Smoothing curve is a simple binomial glm on the immigrant variable using only the effect of Julian day. Julian day 245 is on or one day from the September 1st cutoff used for LSDR. It is displayed as vertical dashed red line.

Yes, while the general trend is the same, there is some variation among year. 2020 saw almost no immigrants. 

__Fit GLM__  
Now let's fit a smple glm using sex, julian day and their interaction
```{r}
strays %<>%
  mutate(immigrant = as.factor(immigrant))

strays %<>%
  mutate(offspring_year = as.factor(offspring_year))

stray_glm <- glm( immigrant ~ jday + sex +jday*sex , family = binomial, data = strays)
summary(stray_glm)
drop1(stray_glm, test = "Chisq")
```

The interaction between the effect of julian day and sex is only marginally significant (p = 0.046, likelihood ratio test). So let's drop it and fit again. We will consider both model fits. 

```{r}
stray_glm2 <- glm( immigrant ~ jday + sex , family = binomial, data = strays)
summary(stray_glm2)
drop1(stray_glm2, test = "Chisq")
```

When we ignore the interaction, the effect both variables are still strongly significant, both by Wald tests and likelihood ratio tests.

```{r, eval = FALSE}
stray_glm2 <- glmer( immigrant ~ jday*sex+ (1|offspring_year) , family = binomial, data = strays)
summary(stray_glm2)
drop1(stray_glm2, test = "Chisq")
```

__GLM Interpretation__  
The response variable is coded with immigrant as the first level and return as the second. Therefore a negative estimated effect of an explanatory variable means that that variable increases the propensity for an immigrant at the trap. (It might be worth releveling the "immigrant" variable factor to make effect estimates and figures consistent with the "probability of immigrant" language used earlier)

So, to interpet the model with the interaction, later in the season there is a significant increase in the proability of immigrants arriving at the trap, and this effect is stronger for males than females. Once you control for julian date, there is no greater propensity for male immigrants to arrive a the trap than for female immigrants.

Let's also plot this model.

```{r}
require(effects)

#let's not use the effect package plotting tools and just get the effects

#eff1 <- predictorEffect("sex_ratio_y_l", final_model, focal.levels = seq(-0.4,0.7,by = 0.1))
eff1 <- predictorEffect("jday", stray_glm)
effdf <- as.data.frame(eff1)


ggplot(data = effdf, aes(x = (jday), y = fit, color = sex))+ 
  geom_line()+geom_smooth( aes(ymin = lower, ymax = upper, fill = sex, colour = sex), stat = "identity") +
  theme_bw()+ylab("1 - Predicted Probability of Immigrant") + scale_color_manual(labels = c("Female", "Male"), name = "Sex", values = c("#228833", "#AA3377")) + scale_fill_manual(labels = c("Female", "Male"), name = "Sex", values = c("#228833", "#AA3377"))+xlab("Julian Day")+geom_vline(aes(xintercept = 245), linetype = "dashed", color  = "red")

```
__Figure N4:__ Predicted probability that an individual arriving at Cougar Trap assigns to a parent released above the Dam vs Julian Day. Vertical red dashed line corresponds to Julian Day 245, on or near September 1st.

__Summary__  
This is somewhat preliminary. We still should do model validation and think about how to incorporate other covariates or whether or not to include random effect of year. 

However, it seems like there is a strong relationship between Julian Day the probability that an NOR individual captured at the Cougar trap is an immigrant (doesn't assign to a parent above the trap). Moreover, there is a sex specific pattern. The same proportion of males and females are likely to be immigrants overall, however later in the season males are more likely to be immigrants. These results fit with our biological expectations. 

With respect to the broader question, the efficacy of LSDR and or recycling, it seems that relatively few (<20%) of NOR salmon sampled at the trap before around July 1st (Julian day 182, most years) are immigrants. By September 1st, the date previously used as the cutoff for LSDR, about 30% of females and about 40% of males are predicted to be immigrants. However, it should be noted that these results are highly variable among years.

These model predictions using data from return years 2013-2020 are somewhat different from the results reported in 2013, 2014 and 2015 using either the new pedigrees (figure N2) or the pedigrees used to produce previous reports (Banks 2014 and Sard 2016). In Sard 2016, the authors found that during 2013 ~78% of NOR salmon sampled at the Cougar Trap after September 1st were likely immigrants. In Banks 2016, the authors found similar results for offspring years 2014 and 2015 (74% and 77%, respectively). These values are in close agreement with those from the newly inferred pedigrees. In one new offspring year for this report (2019), we oberved a similarly high immigrant after September 1st, but it was lower in all other years (2016, 2017, 2018 and 2020).

# Fitness

In this section, we calculate the number of offspring assigned to parents from the pedigree and calculate summary statistics.

## Data Prep

Let's get our first parent-focused dataframe together. This will have one row for each unqiue candidate parent as well as the number of offspring assigned to it in the pedigree. 

```{r}
#first let's get a dataframe that can be easily used to calculate parent level information
# all candidate parents, the number of time they appear in the pedigree and their metadata

parents <- dedup %>%
  filter(cand_parent == TRUE)

father_counts <- pedigree %>%
  group_by(father) %>%
  count() %>%
  rename(parent = father)

mother_counts <- pedigree %>%
  group_by(mother) %>%
  count() %>%
  rename(parent = mother)

parent_counts <- bind_rows(mother_counts, father_counts) 
rm(mother_counts)
rm(father_counts)

parents %<>%
  left_join(parent_counts, by = c("sample_id" = "parent")) %>%
  rename(tlf = n) %>%
  mutate(tlf = replace_na(tlf, 0))
```


## TLF Results

Let's put together some tables of fitness averages by groups. 

Note that TLF only applies when we have ages 3, 4, 5 and 6 offspring for a year. However, our AAM results suggests that fitness using only ages 3, 4 and 5 offspring only slightly underestimates TLF (98% of returning offspring are ages 3, 4 or 5), so using returns from 2010 to 2020, we have TLF estimates for 2007-2014 parent years, a good approximation for 2015, and only partial fitness estimates for 2016 and 2017. These caveats are noted in all subsequent tables and figures

```{r, message = FALSE, warning=FALSE}
# average fitness, by parent year
kable(parents %>%
        filter(year < 2018) %>%
  group_by(year) %>%
  summarise(N = n(), mean_tlf = mean(tlf), sd_tlf = sd(tlf), range = paste(min(tlf), " -  ", max(tlf))) %>%
    mutate(year = as.character(year),
      year = case_when(year == 2015 ~ "2015*",
                       year == 2016 ~ "2016**",
                       year == 2017 ~ "2017**",
                            TRUE ~ year)), align = "c", caption = "Table N11: Total Lifetime Fitness by Parent Year", digits = 2) %>%
  kable_classic(full_width = F, html_font = "Arial")
```
__Table N11:__ TLF per parent year.   
_* Note that 2015 estimates do not include potential year 6 offspring. However we expect these offspring to contribute very little to TLF (~2%)_   
_** Note that 2016 and 2017 offspring do not include potential year 5 and 6 offspring, and potential year 4 5 and 6 offspring, which are expected to substantially contribute to TLF for these parents years_  

```{r, message = FALSE, warning=FALSE}
# average fitness, by parent year
kable(parents %>%
        filter(year < 2018, type %in% c("cougar_trap", "hatchery_outplant")) %>%
  group_by(year, type) %>%
  summarise(N = n(), mean_tlf = mean(tlf), sd_tlf = sd(tlf), range = paste(min(tlf), " -  ", max(tlf))) %>%
        mutate(year = as.character(year),
      year = case_when(year == 2015 ~ "2015*",
                       year == 2016 ~ "2016**",
                       year == 2017 ~ "2017**",
                            TRUE ~ year),
      type = case_when(type == "hatchery_outplant" ~ "hatchery",
                       type == "cougar_trap" ~ "cougar trap")) %>%
    rename(source = type,), align = "c", caption = "Table N12: Total Lifetime Fitness by Parent Year and Source", digits = 2) %>%
  kable_classic(full_width = F, html_font = "Arial")
```
__Table N12:__ TLF per parent year, and parent source. Parent source refers to either*** individuals trapped at the Cougar Trap and released above the dam ("Cougar Trap", NOR and HOR) or individuals trapped at McKEnzie or Leaburg Hatcheries and released above the dam ("Hatchery", HOR)  
_* Note that 2015 estimates do not include potential year 6 offspring. However we expect these offspring to contribute very little to TLF (~2%)_   
_** Note that 2016 and 2017 offspring do not include potential year 5 and 6 offspring, and potential year 4 5 and 6 offspring, which are expected to substantially contribute to TLF for these parents years_   
_*** Note that there are 5 individuals sampled during spawning ground surveys above the dam and 12 precocial males sampled above the dam that were included as candidate parents. None had an offspring assigned to them and they are not presented in this table_ 

```{r, message = FALSE, warning=FALSE}
# average fitness, by parent year
kable(parents %>%
        filter(year < 2018, type %in% c("cougar_trap", "hatchery_outplant")) %>%
  group_by(year, type, sex) %>%
  summarise(N = n(), mean_tlf = mean(tlf), sd_tlf = sd(tlf), range = paste(min(tlf), " -  ", max(tlf))) %>%
        mutate(year = as.character(year),
      year = case_when(year == 2015 ~ "2015*",
                       year == 2016 ~ "2016**",
                       year == 2017 ~ "2017**",
                            TRUE ~ year),
      type = case_when(type == "hatchery_outplant" ~ "hatchery",
                       type == "cougar_trap" ~ "cougar trap")) %>%
    rename(source = type,), align = "c", caption = "Table N13: Total Lifetime Fitness by Parent Year, Source and Sex", digits = 2) %>%
  kable_classic(full_width = F, html_font = "Arial")
```
__Table N13:__ TLF per parent year, parent source and sex. Parent source refers to either*** individuals trapped at the Cougar Trap and released above the dam ("Cougar Trap", NOR and HOR) or individuals trapped at McKEnzie or Leaburg Hatcheries and released above the dam ("Hatchery", HOR)  
_* Note that 2015 estimates do not include potential year 6 offspring. However we expect these offspring to contribute very little to TLF (~2%)_   
_** Note that 2016 and 2017 offspring do not include potential year 5 and 6 offspring, and potential year 4 5 and 6 offspring, which are expected to substantially contribute to TLF for these parents years_   
_*** Note that there are 5 individuals sampled during spawning ground surveys above the dam and 12 precocial males sampled above the dam that were included as candidate parents. None had an offspring assigned to them and they are not presented in this table_ 

```{r, message = FALSE, warning=FALSE}
# average fitness, by parent year
kable(parents %>%
        filter(year < 2018, type %in% c("cougar_trap", "hatchery_outplant")) %>%
  group_by(year, origin, sex) %>%
  summarise(N = n(), mean_tlf = mean(tlf), sd_tlf = sd(tlf), range = paste(min(tlf), " -  ", max(tlf))) %>%
        mutate(year = as.character(year),
      year = case_when(year == 2015 ~ "2015*",
                       year == 2016 ~ "2016**",
                       year == 2017 ~ "2017**",
                            TRUE ~ year)
      ) %>%
    pivot_wider(id_cols = c(year, sex), names_from = origin, values_from = c(N, mean_tlf, sd_tlf, range) ) %>%
    select(year, sex, N_HOR, mean_tlf_HOR, sd_tlf_HOR, range_HOR, N_NOR, mean_tlf_NOR, sd_tlf_NOR, range_NOR), align = "c", caption = "Table N13c: Total Lifetime Fitness by Parent Year, Origin, and Sex", digits = 2) %>%
  kable_classic(full_width = F, html_font = "Arial")
```
__Table N13b:__ TLF per parent year, origin and sex. Note NA origin individuals are excluded. 
_* Note that 2015 estimates do not include potential year 6 offspring. However we expect these offspring to contribute very little to TLF (~2%)_   
_** Note that 2016 and 2017 offspring do not include potential year 5 and 6 offspring, and potential year 4 5 and 6 offspring, which are expected to substantially contribute to TLF for these parents years_   
_*** Note that there are 5 individuals sampled during spawning ground surveys above the dam and 12 precocial males sampled above the dam that were included as candidate parents. None had an offspring assigned to them and they are not presented in this table_ 


```{r, message = FALSE, warning=FALSE}
# average fitness, by parent year
kable(parents %>%
        filter(year < 2018, type %in% c("cougar_trap", "hatchery_outplant")) %>%
  group_by(year, type, origin, sex) %>%
  summarise(N = n(), mean_tlf = mean(tlf), sd_tlf = sd(tlf), range = paste(min(tlf), " -  ", max(tlf))) %>%
        mutate(year = as.character(year),
      year = case_when(year == 2015 ~ "2015*",
                       year == 2016 ~ "2016**",
                       year == 2017 ~ "2017**",
                            TRUE ~ year),
      type = case_when(type == "hatchery_outplant" ~ "hatchery",
                       type == "cougar_trap" ~ "cougar trap")) %>%
    rename(source = type,), align = "c", caption = "Table N13c: Total Lifetime Fitness by Parent Year, Source Origin, and Sex", digits = 2) %>%
  kable_classic(full_width = F, html_font = "Arial")
```
__Table N13c:__ TLF per parent year, parent source, origin and sex. Parent source refers to either*** individuals trapped at the Cougar Trap and released above the dam ("Cougar Trap", NOR and HOR) or individuals trapped at McKEnzie or Leaburg Hatcheries and released above the dam ("Hatchery", HOR)  
_* Note that 2015 estimates do not include potential year 6 offspring. However we expect these offspring to contribute very little to TLF (~2%)_   
_** Note that 2016 and 2017 offspring do not include potential year 5 and 6 offspring, and potential year 4 5 and 6 offspring, which are expected to substantially contribute to TLF for these parents years_   
_*** Note that there are 5 individuals sampled during spawning ground surveys above the dam and 12 precocial males sampled above the dam that were included as candidate parents. None had an offspring assigned to them and they are not presented in this table_ 


Let's also put together a figure to make any trend easier to identify.
```{r, message = FALSE, warning=FALSE}
plot_data <- parents %>%
        filter(year < 2016, type %in% c("cougar_trap", "hatchery_outplant")) %>%
  group_by(year, type, sex) %>%
  summarise(N = n(), mean_tlf = mean(tlf), sd_tlf = sd(tlf), se_tlf = sd(tlf)/sqrt(n()), range = paste(min(tlf), " -  ", max(tlf))) %>%
  mutate(type = case_when(type == "hatchery_outplant" ~ "hatchery",
                       type == "cougar_trap" ~ "cougar trap")) %>%
  ungroup() %>%
  unite("type_sex", type, sex)

ggplot(data = plot_data, aes(x = year, y = mean_tlf, color = c(type_sex)))+geom_point(size = 2)+geom_line(size = 1.5, alpha = 0.5)+geom_errorbar(aes(ymin=mean_tlf-se_tlf, ymax=mean_tlf+se_tlf), width=.1)+scale_color_viridis_d(labels = c("Cougar Trap Female", "Cougar Trap Male", "Hatchery Female", "Hatchery Male"), name = "Source, Sex")+theme_classic()+scale_x_continuous(n.breaks = 9)+xlab("Year")+ylab("TLF")


plot_data <- parents %>%
        filter(year < 2016, !(is.na(origin))) %>%
  group_by(year, origin, sex) %>%
  summarise(N = n(), mean_tlf = mean(tlf), sd_tlf = sd(tlf), se_tlf = sd(tlf)/sqrt(n()), range = paste(min(tlf), " -  ", max(tlf))) %>%
  ungroup() %>%
  unite("origin_sex", origin, sex)

ggplot(data = plot_data, aes(x = year, y = mean_tlf, color = c(origin_sex)))+geom_point(size = 2)+geom_line(size = 1.5, alpha = 0.5)+geom_errorbar(aes(ymin=mean_tlf-se_tlf, ymax=mean_tlf+se_tlf), width=.1)+scale_color_bright(labels = c("HOR Female", "HOR Male", "NOR Female", "NOR Male"), name = "Origin, Sex")+theme_classic()+scale_x_continuous(n.breaks = 9, labels = c("2007", "2008", "2009", "2010", "2011", "2012", "2013", "2014", "2015*"))+xlab("Year")+ylab("TLF")


```
__Figure N5:__ Mean TLF* and standard error by Candidate Parent Source, Sex and Year. Source refers to either Cougar Trap (includes NOR and HOR) or Hatchery (only HOR).  
_* Note that 2015 estimates do not include potential year 6 offspring. However we expect these offspring to contribute very little to TLF (~2%)_   

From the figure, some trends appear that might be more difficult for some to notice in the tables:  
(1) Parents from Cougar Trap usually ahve higher TLF than parents from the hatchery.  
(2) Male TLF is almost always lower than female TLF among parents outplanted from the hatchery, but not among parents from Cougar trap.  
(3) Changes in fitness from year to year appear correlated between Cougar Trap and the hatchery.  

Finally let's put together a summary table of mean TLF for sexes, and origin, not divided by year to use in the text.

```{r, eval = FALSE}
kable(parents %>%
        filter(year < 2016) %>%
  group_by(origin) %>%
  summarise(N = n(), mean_tlf = mean(tlf), sd_tlf = sd(tlf), range = paste(min(tlf), " -  ", max(tlf))
      ),
     align = "c", caption = "", digits = 2) %>%
  kable_classic(full_width = F, html_font = "Arial")

kable(parents %>%
        filter(year < 2016) %>%
  group_by(sex) %>%
  summarise(N = n(), mean_tlf = mean(tlf), sd_tlf = sd(tlf), range = paste(min(tlf), " -  ", max(tlf))
      ),
     align = "c", caption = "", digits = 2) %>%
  kable_classic(full_width = F, html_font = "Arial")

kable(parents %>%
        filter(year < 2016) %>%
  group_by() %>%
  summarise(N = n(), mean_tlf = mean(tlf), sd_tlf = sd(tlf), range = paste(min(tlf), " -  ", max(tlf))
      ),
     align = "c", caption = "", digits = 2) %>%
  kable_classic(full_width = F, html_font = "Arial")
```


# Cohort Replacement Rates

Here we estimate the cohort replacement rate (CRR) across different groups of parents. 

CRR is defined as the number of spawners produced by a spawner. 

Results are prepared for each of the following groups:   

* All parents, by year  
* All parents, by year and sex

```{r, message = FALSE, warning=FALSE}
a <- pedigree_meta %>%
  filter(!(father_type == "none" & mother_type == "none")) %>% 
  group_by(parent_year) %>%
  summarise(offspring_n = n())

b <- dedup %>%
  filter(cand_parent == TRUE) %>%
  count(year) %>%
  rename(parent_year = year, n_candidate_parents = n)

kable(left_join(a,b) %>%
        mutate(parent_year = as.character(parent_year),
      parent_year = case_when(parent_year == 2015 ~ "2015*",
                       parent_year == 2016 ~ "2016**",
                       parent_year == 2017 ~ "2017**",
                            TRUE ~ parent_year),
      CRR = offspring_n / n_candidate_parents ), align = "c", caption = "Table N13: Cohort Replacement Rate") %>% kable_classic(full_width = F, html_font = "Arial") %>%
  kable_styling(fixed_thead = T) 

rm(a)
rm(b)




```
__Table N13:__ Cohort Replacement Rate (CRR) per parent year. CRR is defined as the number of spawners produced by a spawner. In our case it is the number of offspring successfully assigned to at least one parent in a given year, divided by the number of candidate parents in that year.  
_* Note that 2015 estimates do not include potential year 6 offspring. However we expect these offspring to contribute very little to TLF (~2%)_   
_** Note that 2016 and 2017 offspring do not include potential year 5 and 6 offspring, and potential year 4 5 and 6 offspring, which are expected to substantially contribute to TLF for these parents years_  



```{r, message = FALSE, warning = FALSE}
# add offspring sex to pedigree_meta

pedigree_meta %<>%
  left_join(select(dedup, sex, sample_id), by = c("offspring_sample_id" = "sample_id")) %>%
  rename(offspring_sex = sex)

father_male_offspring_counts <- pedigree_meta %>%
  filter(offspring_sex == "M") %>%
  group_by(father) %>%
  count() %>%
  rename(parent = father)

mother_female_offspring_counts <- pedigree_meta %>%
  filter(offspring_sex == "F") %>%
  group_by(mother) %>%
  count() %>%
  rename(parent = mother)

parent_counts_same_sex <- bind_rows(mother_female_offspring_counts, father_male_offspring_counts) 
rm(father_male_offspring_counts)
rm(mother_female_offspring_counts)

parents %<>%
  left_join(parent_counts_same_sex, by = c("sample_id" = "parent")) %>%
  rename(same_sex_offspring = n) %>%
  mutate(same_sex_offspring = replace_na(same_sex_offspring, 0))

kable(parents %>%
  group_by(year, sex) %>%
    filter(year < 2018) %>%
  summarise(n = n(), crr_sex = sum(same_sex_offspring)/n(), n_offspring_same_sex = sum(same_sex_offspring)) %>%
    mutate(year = as.character(year),
      year = case_when(year == 2015 ~ "2015*",
                       year == 2016 ~ "2016**",
                       year == 2017 ~ "2017**",
                            TRUE ~ year)),
       align = "c", digits = 2, caption = "Table N14") %>%
  kable_classic(full_width = F, html_font = "Arial") %>%
  kable_styling(fixed_thead = T) %>%
  scroll_box(height = "400px")
# Let's check one of these to make sure the code is working correctly. In 2016, there were 452 male outplants. These 452 potential fathers appear in the final pedigree 1092 times. Of these 1092 offspring, 723 is male. Therefore the correct CRR for 2016 male outplants is 1.5995575. This matches the table.
```
__Table N14:__ Sex specific CRR by year, sex. Here CRR refers to the nuber of female offspring produced by female parents, or the number of male offspring produced by male parents.
_* Note that 2015 estimates do not include potential year 6 offspring. However we expect these offspring to contribute very little to TLF (~2%)_   
_** Note that 2016 and 2017 offspring do not include potential year 5 and 6 offspring, and potential year 4 5 and 6 offspring, which are expected to substantially contribute to TLF for these parents years_   



# Effective Number of Breeders

Calculated Nb using LD method from NeEstimator v2.1. Used GUI, so only logging the parameters used here, not calculating the values.

Parameters:  
S+ option (exclude singletons)  
CIs: 95% confidence intervals from jacknife re-sampling method  
Data: Data for a given year is the assigned offspring of that year  

## Data Prep
Let's create the input data for NeEstimator. We'll take advantage of a wrapper function from adegenet and rLDNE to output a genepop file all assigned offspring for each parent year.

__2007__

```{r, message=FALSE, warning=FALSE, eval = FALSE}
# Here we filter the genotype data to get only offspring from 2007 cohort
offspring_of_2007 <- pedigree_meta %>%
  filter(mother_year == 2007 | father_year ==2007) %>%
  pull(offspring_sample_id)

gts_off_of_2007 <- dedup %>%
  filter(sample_id %in% offspring_of_2007) %>%
  select(sample_id, starts_with("Ot")) %>% #grab the genotypes
  mutate(across(.cols = everything(), ~na_if(., "0")))

#now we put bth alleles into a single column for each locus
gts_off_of_2007 %<>%
  gather(key = var, value = value, -sample_id) %>%
  mutate(var = str_extract(var, "\\d+") %>% as.numeric()) %>% 
  group_by(sample_id, var) %>%
  summarise(combined = paste(value, collapse = "")) %>% 
  spread(key = var, value = combined) 

# add a dummy pop variable for conversion, fix NAs
gts_off_of_2007 %<>%
  add_column(pop = "p") %>%
  relocate(sample_id, pop) %>%
  mutate(across(.cols = everything(), ~str_replace(., "NANA", "000000")))

write_genepop_zlr(loci = gts_off_of_2007[,3:ncol(gts_off_of_2007)],pops = gts_off_of_2007$pop,ind.ids = gts_off_of_2007$sample_id,folder = "neestimator/",filename ="genepop_2007.txt",ncode = 3,diploid = T)


```

__2008__
```{r, message=FALSE, warning=FALSE, eval = FALSE}
# Here we filter the genotype data to get only offspring from 2008 cohort
offspring_of_2008 <- pedigree_meta %>%
  filter(mother_year == 2008 | father_year ==2008) %>%
  pull(offspring_sample_id)

gts_off_of_2008 <- dedup %>%
  filter(sample_id %in% offspring_of_2008) %>%
  select(sample_id, starts_with(c("Ot"))) %>% #grab the genotypes
  mutate(across(.cols = everything(), ~na_if(., "0")))

#now we put bth alleles into a single column for each locus
gts_off_of_2008 %<>%
  gather(key = var, value = value, -sample_id) %>%
  mutate(var = str_extract(var, "\\d+") %>% as.numeric()) %>% 
  group_by(sample_id, var) %>%
  summarise(combined = paste(value, collapse = "")) %>% 
  spread(key = var, value = combined) 

# add a dummy pop variable for conversion, fix NAs
gts_off_of_2008 %<>%
  add_column(pop = "p") %>%
  relocate(sample_id, pop) %>%
  mutate(across(.cols = everything(), ~str_replace(., "NANA", "000000")))

write_genepop_zlr(loci = gts_off_of_2008[,3:ncol(gts_off_of_2008)],pops = gts_off_of_2008$pop,ind.ids = gts_off_of_2008$sample_id,folder = "neestimator/",filename ="genepop_2008.txt",ncode = 3,diploid = T)


```

__2009__
```{r, message=FALSE, warning=FALSE, eval = FALSE}
# Here we filter the genotype data to get only offspring from 2009 cohort
offspring_of_2009 <- pedigree_meta %>%
  filter(mother_year == 2009 | father_year ==2009) %>%
  pull(offspring_sample_id)

gts_off_of_2009 <- dedup %>%
  filter(sample_id %in% offspring_of_2009) %>%
  select(sample_id, starts_with(c("Ot"))) %>% #grab the genotypes
  mutate(across(.cols = everything(), ~na_if(., "0")))

#now we put bth alleles into a single column for each locus
gts_off_of_2009 %<>%
  gather(key = var, value = value, -sample_id) %>%
  mutate(var = str_extract(var, "\\d+") %>% as.numeric()) %>% 
  group_by(sample_id, var) %>%
  summarise(combined = paste(value, collapse = "")) %>% 
  spread(key = var, value = combined) 

# add a dummy pop variable for conversion, fix NAs
gts_off_of_2009 %<>%
  add_column(pop = "p") %>%
  relocate(sample_id, pop) %>%
  mutate(across(.cols = everything(), ~str_replace(., "NANA", "000000")))

write_genepop_zlr(loci = gts_off_of_2009[,3:ncol(gts_off_of_2009)],pops = gts_off_of_2009$pop,ind.ids = gts_off_of_2009$sample_id,folder = "neestimator/",filename ="genepop_2009.txt",ncode = 3,diploid = T)


```

__2010__
```{r, message=FALSE, warning=FALSE, eval = FALSE}
# Here we filter the genotype data to get only offspring from 2010 cohort
offspring_of_2010 <- pedigree_meta %>%
  filter(mother_year == 2010 | father_year ==2010) %>%
  pull(offspring_sample_id)

gts_off_of_2010 <- dedup %>%
  filter(sample_id %in% offspring_of_2010) %>%
  select(sample_id, starts_with(c("Ot"))) %>% #grab the genotypes
  mutate(across(.cols = everything(), ~na_if(., "0")))

#now we put bth alleles into a single column for each locus
gts_off_of_2010 %<>%
  gather(key = var, value = value, -sample_id) %>%
  mutate(var = str_extract(var, "\\d+") %>% as.numeric()) %>% 
  group_by(sample_id, var) %>%
  summarise(combined = paste(value, collapse = "")) %>% 
  spread(key = var, value = combined) 

# add a dummy pop variable for conversion, fix NAs
gts_off_of_2010 %<>%
  add_column(pop = "p") %>%
  relocate(sample_id, pop) %>%
  mutate(across(.cols = everything(), ~str_replace(., "NANA", "000000")))

write_genepop_zlr(loci = gts_off_of_2010[,3:ncol(gts_off_of_2010)],pops = gts_off_of_2010$pop,ind.ids = gts_off_of_2010$sample_id,folder = "neestimator/",filename ="genepop_2010.txt",ncode = 3,diploid = T)


```

__2011__
```{r, message=FALSE, warning=FALSE, eval = FALSE}
# Here we filter the genotype data to get only offspring from 2011 cohort
offspring_of_2011 <- pedigree_meta %>%
  filter(mother_year == 2011 | father_year ==2011) %>%
  pull(offspring_sample_id)

gts_off_of_2011 <- dedup %>%
  filter(sample_id %in% offspring_of_2011) %>%
  select(sample_id, starts_with(c("Ot"))) %>% #grab the genotypes
  mutate(across(.cols = everything(), ~na_if(., "0")))

#now we put bth alleles into a single column for each locus
gts_off_of_2011 %<>%
  gather(key = var, value = value, -sample_id) %>%
  mutate(var = str_extract(var, "\\d+") %>% as.numeric()) %>% 
  group_by(sample_id, var) %>%
  summarise(combined = paste(value, collapse = "")) %>% 
  spread(key = var, value = combined) 

# add a dummy pop variable for conversion, fix NAs
gts_off_of_2011 %<>%
  add_column(pop = "p") %>%
  relocate(sample_id, pop) %>%
  mutate(across(.cols = everything(), ~str_replace(., "NANA", "000000")))

write_genepop_zlr(loci = gts_off_of_2011[,3:ncol(gts_off_of_2011)],pops = gts_off_of_2011$pop,ind.ids = gts_off_of_2011$sample_id,folder = "neestimator/",filename ="genepop_2011.txt",ncode = 3,diploid = T)


```

__2012__
```{r, message=FALSE, warning=FALSE, eval = FALSE}
# Here we filter the genotype data to get only offspring from 2012 cohort
offspring_of_2012 <- pedigree_meta %>%
  filter(mother_year == 2012 | father_year ==2012) %>%
  pull(offspring_sample_id)

gts_off_of_2012 <- dedup %>%
  filter(sample_id %in% offspring_of_2012) %>%
  select(sample_id, starts_with(c("Ot"))) %>% #grab the genotypes
  mutate(across(.cols = everything(), ~na_if(., "0")))

#now we put bth alleles into a single column for each locus
gts_off_of_2012 %<>%
  gather(key = var, value = value, -sample_id) %>%
  mutate(var = str_extract(var, "\\d+") %>% as.numeric()) %>% 
  group_by(sample_id, var) %>%
  summarise(combined = paste(value, collapse = "")) %>% 
  spread(key = var, value = combined) 

# add a dummy pop variable for conversion, fix NAs
gts_off_of_2012 %<>%
  add_column(pop = "p") %>%
  relocate(sample_id, pop) %>%
  mutate(across(.cols = everything(), ~str_replace(., "NANA", "000000")))

write_genepop_zlr(loci = gts_off_of_2012[,3:ncol(gts_off_of_2012)],pops = gts_off_of_2012$pop,ind.ids = gts_off_of_2012$sample_id,folder = "neestimator/",filename ="genepop_2012.txt",ncode = 3,diploid = T)


```

__2013__
```{r, message=FALSE, warning=FALSE, eval = FALSE}
# Here we filter the genotype data to get only offspring from 2013 cohort
offspring_of_2013 <- pedigree_meta %>%
  filter(mother_year == 2013 | father_year ==2013) %>%
  pull(offspring_sample_id)

gts_off_of_2013 <- dedup %>%
  filter(sample_id %in% offspring_of_2013) %>%
  select(sample_id, starts_with(c("Ot"))) %>% #grab the genotypes
  mutate(across(.cols = everything(), ~na_if(., "0")))

#now we put bth alleles into a single column for each locus
gts_off_of_2013 %<>%
  gather(key = var, value = value, -sample_id) %>%
  mutate(var = str_extract(var, "\\d+") %>% as.numeric()) %>% 
  group_by(sample_id, var) %>%
  summarise(combined = paste(value, collapse = "")) %>% 
  spread(key = var, value = combined) 

# add a dummy pop variable for conversion, fix NAs
gts_off_of_2013 %<>%
  add_column(pop = "p") %>%
  relocate(sample_id, pop) %>%
  mutate(across(.cols = everything(), ~str_replace(., "NANA", "000000")))

write_genepop_zlr(loci = gts_off_of_2013[,3:ncol(gts_off_of_2013)],pops = gts_off_of_2013$pop,ind.ids = gts_off_of_2013$sample_id,folder = "neestimator/",filename ="genepop_2013.txt",ncode = 3,diploid = T)


```

__2014__
```{r, message=FALSE, warning=FALSE, eval = FALSE}
# Here we filter the genotype data to get only offspring from 2014 cohort
offspring_of_2014 <- pedigree_meta %>%
  filter(mother_year == 2014 | father_year ==2014) %>%
  pull(offspring_sample_id)

gts_off_of_2014 <- dedup %>%
  filter(sample_id %in% offspring_of_2014) %>%
  select(sample_id, starts_with(c("Ot"))) %>% #grab the genotypes
  mutate(across(.cols = everything(), ~na_if(., "0")))

#now we put bth alleles into a single column for each locus
gts_off_of_2014 %<>%
  gather(key = var, value = value, -sample_id) %>%
  mutate(var = str_extract(var, "\\d+") %>% as.numeric()) %>% 
  group_by(sample_id, var) %>%
  summarise(combined = paste(value, collapse = "")) %>% 
  spread(key = var, value = combined) 

# add a dummy pop variable for conversion, fix NAs
gts_off_of_2014 %<>%
  add_column(pop = "p") %>%
  relocate(sample_id, pop) %>%
  mutate(across(.cols = everything(), ~str_replace(., "NANA", "000000")))

write_genepop_zlr(loci = gts_off_of_2014[,3:ncol(gts_off_of_2014)],pops = gts_off_of_2014$pop,ind.ids = gts_off_of_2014$sample_id,folder = "neestimator/",filename ="genepop_2014.txt",ncode = 3,diploid = T)


```

__2015__
```{r, message=FALSE, warning=FALSE, eval = FALSE}
# Here we filter the genotype data to get only offspring from 2015 cohort
offspring_of_2015 <- pedigree_meta %>%
  filter(mother_year == 2015 | father_year ==2015) %>%
  pull(offspring_sample_id)

gts_off_of_2015 <- dedup %>%
  filter(sample_id %in% offspring_of_2015) %>%
  select(sample_id, starts_with(c("Ot"))) %>% #grab the genotypes
  mutate(across(.cols = everything(), ~na_if(., "0")))

#now we put bth alleles into a single column for each locus
gts_off_of_2015 %<>%
  gather(key = var, value = value, -sample_id) %>%
  mutate(var = str_extract(var, "\\d+") %>% as.numeric()) %>% 
  group_by(sample_id, var) %>%
  summarise(combined = paste(value, collapse = "")) %>% 
  spread(key = var, value = combined) 

# add a dummy pop variable for conversion, fix NAs
gts_off_of_2015 %<>%
  add_column(pop = "p") %>%
  relocate(sample_id, pop) %>%
  mutate(across(.cols = everything(), ~str_replace(., "NANA", "000000")))

write_genepop_zlr(loci = gts_off_of_2015[,3:ncol(gts_off_of_2015)],pops = gts_off_of_2015$pop,ind.ids = gts_off_of_2015$sample_id,folder = "neestimator/",filename ="genepop_2015.txt",ncode = 3,diploid = T)


```

## Results

Neestimator results are not formatted to be easily parsed by machine. Instead, wrote results manually to a spreadsheet.

```{r, message=FALSE, warning=FALSE}
ne <- read_tsv("neestimator/ne_estimator_results.txt")

# let's build a table by parent year of number of candidate parents, number of successful parents, and number of assigned offspring
a <- parents %>%
  filter(year <2016) %>%
  group_by(year) %>%
  summarise(n_cand = n(), n_successful = sum(tlf >0))

b <- pedigree_meta %>%
  count(parent_year) %>%
  filter(parent_year < 2016) %>%
  rename(year = parent_year)

nb_table <- left_join(a,b) %>%
  rename(n_offspring = n)
  
#left_join(nb_table, ne) #just to check the offspring datasets were correct, looks good!

kable(nb_table %<>%
  left_join(ne) %>%
  select(-N_offspring, Nb = Ne) %>%
    mutate(year = as.character(year),
           year = case_when(year == "2015" ~ "2015*",
                            TRUE ~ year),
           Nb_Nsuccess_ratio = Nb/n_successful),
       align = "c", digits = 2, caption = "Table N15: Effective Number of Breeders") %>%
  kable_classic(full_width = F, html_font = "Arial") 
  
```
__Table N15__ Effective number of breeders (Nb) per parent year as estimated by NeEstimator. Number of candidate parents (N_cand) is the number of salmon released above the Cougar Dam in a given year that were sampled, and successfully genotyped. N_successful is the number of candidate parents with one or more offspring in the pedigree. N_offspring is the nmber of offspring assigned to candidate parents released above the dam that parent year. 95% Confidence intervals based on jack-knife are provided. Finally the Nb_Nsuccess ratio is the Nb estimate divided by the number of successful breeders. 

# Predictors of Fitness

In this section we fit a GLMM on TLF of salmon released above the dam.

## Mixed Modeling Approach Overview

We primarily follow the approach described in Zuur et al 2009. Mixed Effects Models and Extensions in Ecology with R.

(0) __Define Predictors__ BEfore any analysis, we need to think about what predictors are in the dataset or can be extracted from it and how they may interact.
(1) __Exploratory Data Analysis:__ First we explore the relationships between all predictors in the dataset.  
(2) __Multicollinearity:__  In addition to our findings from EDA above, we fit main effects models and calculate variance inflation factors to identify multicollinearity among main effects.  
(3) __Random Effects Model Selection:__ After removing effects contributing to multicollinearity in a main effects only model, we fit an otherwise saturated models including all main effects and interactions, but varied which random effects were included. Model fit was by REML. We chose the best random effects structure by AIC and LRTs.  
(4) __Fixed Effects Model Selection:__ We then conducted model selection on the fixed effects using LRTs and backward stepwise selection on Wald tests for signficant effects (p < 0.05 not multiple comparison corrected). Model fit was by ML. For the LRTs we stepwise dropped non-significant interaction terms from the model, to evaluate if main effects were significant.  
(5) __Model Validation:__ We validated the model using simulated residuals from the DHARMa package.  
(6) __Estimated Marginal Means and Effect:__ To improve biological intepretation of signficant predictors of fitness, we estimated marginal means for significant effects.  

## Predictors
There are a lot of potential predictors and interactions. Here we describe each and rationalize which to consider interactions between.

(1) __Release Day__: What day were individuals released? We will transform date into Julian Day. Here we can expect an optimum so we may want to consider a non-linear effect.    
(2) __Release Location__: There are several release locations at various points above the dam from the head of the reservoir all the way to 37km upriver. We can consider release location as a factor or rkm as a continuous variable. We will consider both and only retain one.     
(3) __Origin__: What is the origin of the individual, NOR or HOR?    
  (a) Origin of Parents: Since our pedigree includes so many years we can also consider (for NOR individuals) whether an individuals descends from a HORxHOR, HORxNOR, or NORxNOR cross. This one is a bit complicated though, and will drastically reduce sample size. Since our mixed modeling tools are not tolerant of missing data will will not inclde this, but will return to it in a post-hoc analysis.      
  (b) Origin of Grandparents: Same as above but for grandparents. Unlikely to include since we have so few F2s with fitness estimates in the dataset.   
(4) __Source__: Was the individual trucked from the Cougar Trap of the Hatchery. This is expected to be strongly collinear with origin, so it is unlikely to be retained in the model, but there are 218 cougar trap HORs that can be compared to hatchery outplant HORs.    
(5) __Release Group Variables__: These are variables nested within release group, the set of fish released together from the same source on the same day at the same location.   
  (a) Release group: Used as a random effect, the release group itself. Fitting as a random effect allows us to beneift from shrinkage to improve estimates at fixed effects, and we can also gain an understanding of how inter-release group variance contributes to variance in fitness overall.   
  (b) Release Group Sex Ratio: What is the sex ratio of fish in a release group? If individuals from a single release group are more likely to spawn together than individuals from different release group, sex ratio might matter. Fit as non-linear effect as there is expected to be an optimum.    
  (c) Release Group Density: What is the density of a release group? Is there an optimum number to release at one time? Fit as non-linear effect.  
(6) __Annual Variables__: These are variables nested within year.  
  (a) Year: Random effect of year.   
  (b) Annual Density: Is there an optimum density for releases? Fit as non-linear effect.  
  (c) Annual Sex Ratio: This was the single most important predictor in the North Santiam. Fit as non-linear effect as there is expected to be an optimum.    
(7) __Size__: We have an estimate of size at maturity for about half (4321/8985) of our candidate parents. Our modeling tools are not compatible with missing data, so this would effectively cut our sample size in half. We chose not to fit it, but will consider it in a post hoc analysis. For example, it is known that origin effects on fitness are mediated at least somewhat through size, so if origin has an effect we should examine if there is a size interaction.  

__Interactions__  
* Sex * Sex Ratios: This one seems obvious  
* Sex * Release Day: This one follows from ecology of salmon spawning. Selective pressures on males and females differ over time during spawning.  
* Sex * Origin: Previous work in this system found this interaction. We should follow up here.  

There are other interactions that might be interesting (e.g sex* release group density), but each one costs a lot of degrees of freedom, especially for release day, which might be fit as a non-linear effect. Let's ignore all other interactions.  

## Data, EDA and Multicollinearity

Here we prepare the dataset for modeling and conduct some exploratory data analysis.

Our dataset includes all candidate parents (i.e. released above the dam) from 2007 to 2015. Note that 2015 TLF does not include age 6 offsrping in their TLFs, but our AAM analysis suggests year 6 offspring contribute little to TLF (~2%).


```{r}
mm_data <-  parents %>%
  filter( year <2016) %>%
  select(date, sex, release, rkm, origin, year, type, tlf) %>%
  drop_na() %>%
  mutate(jday = as.numeric(format(date, "%j"))) %>% #julian day in this case: days since the first day of the year
  mutate(jday_c = scale(jday, scale = F), #center the julian day to help with convergence
         sex = as.factor(sex),
         release= as.factor(release),
         year = as.factor(year),
         group = as.factor(paste(date, release, type)))

# The dataset include 7438 individuals

# lets add density
dens <- mm_data %>%
 group_by(jday, release, year, type) %>%
  summarise(density = n())

mm_data %<>%
  left_join(dens)

# lets add overall size of release in a year
dens <- mm_data %>%
 group_by(year) %>%
  summarise(annual_n = n())

mm_data %<>%
  left_join(dens)


# lets add sex ratio
#build release group sex ratio variable
f <- mm_data %>% 
  filter(sex == "F") %>%
  group_by(release, jday, year, type) %>% 
  summarise(n_female_rg = n()) 

mm_data %<>%
  left_join(f)

m <- mm_data %>% 
  filter(sex == "M") %>%
  group_by(release, jday, year, type) %>% 
  summarise(n_male_rg = n()) 

mm_data %<>%
  left_join(m) %>%
  mutate(sex_ratio_rg = n_male_rg/n_female_rg)

# maybe the release groups all mix thoroughly spawn together and we should fit sex ratio at the level of year
f <- mm_data %>% 
  filter(sex == "F") %>%
  group_by( year) %>% 
  summarise(n_female_y = n()) 

mm_data %<>%
  left_join(f)

m <- mm_data %>% 
  filter(sex == "M") %>%
  group_by( year) %>% 
  summarise(n_male_y = n()) 

mm_data %<>%
  left_join(m) %>%
  mutate(sex_ratio_y = n_male_y/n_female_y)


mm_data %<>%
  mutate(sex_ratio_rg_l = log(sex_ratio_rg),
         sex_ratio_y_l = log(sex_ratio_y))

# there are a bunch of days where the only males or only females are released, this means we wind up with NAs when trying to log transform release group level variable, reducing sample size by 375 individuals. If we don't use that variable (release group sex ratio), then we can get rid of this dataset and use one with the full set of individuals, let's remember this

mm_data %<>%
  drop_na()

# oops forgot to convert origin to a factor
mm_data %<>%
  mutate(origin = as.factor(origin))

```

Let's explore the data a bit too and look for issues with collinearity. We will assume that fitness in Mckenzie is best fit with a negative binomial, just like in North Santiam, but we'll explore the possibility of using other distributions as well (poisson, hurdle and zero inflation).

```{r}
##################################################################
##################################################################
#Here are some functions that we took from the pairs help file and
#modified, or wrote ourselves. To cite these, use the r citation: citation()

panel.cor <- function(x, y, digits=1, prefix="", cex.cor = 6)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r1=cor(x,y,use="pairwise.complete.obs")
  r <- abs(cor(x, y,use="pairwise.complete.obs"))
  txt <- format(c(r1, 0.123456789), digits=digits)[1]
  txt <- paste(prefix, txt, sep="")
  if(missing(cex.cor)) { cex <- 0.9/strwidth(txt) } else {
     cex = cex.cor}
  text(0.5, 0.5, txt, cex = cex * r)
}

##################################################################
panel.smooth2=function (x, y, col = par("col"), bg = NA, pch = par("pch"),
                        cex = 1, col.smooth = "black", span = 2/3, iter = 3, ...)
{
  points(x, y, pch = pch, col = col, bg = bg, cex = cex)
  ok <- is.finite(x) & is.finite(y)
  if (any(ok))
    lines(stats::lowess(x[ok], y[ok], f = span, iter = iter),
          col = 1, ...)
}

##################################################################
panel.lines2=function (x, y, col = par("col"), bg = NA, pch = par("pch"),
                       cex = 1, ...)
{
  points(x, y, pch = pch, col = col, bg = bg, cex = cex)
  ok <- is.finite(x) & is.finite(y)
  if (any(ok)){
    tmp=lm(y[ok]~x[ok])
    abline(tmp)}
}

##################################################################
panel.hist <- function(x, ...)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(usr[1:2], 0, 1.5) )
  h <- hist(x, plot = FALSE)
  breaks <- h$breaks; nB <- length(breaks)
  y <- h$counts; y <- y/max(y)
  rect(breaks[-nB], 0, breaks[-1], y, col="white", ...)
}



```

```{r}
select(mm_data, tlf, sex, jday, density,sex_ratio_y_l, sex_ratio_rg_l, annual_n , release, origin) %>%
  pairs(., lower.panel = panel.cor, diag.panel = panel.hist, upper.panel = panel.smooth2)

mm_data %>%
  select(tlf, sex, jday, density,sex_ratio_y_l, sex_ratio_rg_l, annual_n , release, origin) %>%
  mutate(tlf = log(tlf)) %>%
  pairs(., lower.panel = panel.cor, diag.panel = panel.hist, upper.panel = panel.smooth2)

```

The bi-plots are revealing some issues with balance and collinearity. We will explore mutlicollinearity with VIFs, but wrt balance, it looks like annual density (total number of individuals released in a year), might be a problem. There is one year where many more individuals were released than others. This might cause an issue fitting models. Let's exclude it from the modeling. 

Let's fit a model of fixed effects and look for collinearity among predictors


```{r}
beyond_opt_main <- glm.nb(tlf ~ poly(jday_c,2) + sex + poly(density, 2) + poly(sex_ratio_y_l,2) + poly(sex_ratio_rg_l,2) +  origin + release , data = mm_data)
kable(vif(beyond_opt_main), caption = "Variance Inflation Factors for fully saturated fixed effect model") %>% kable_classic(full_width = F, html_font = "Cambria" ) 
```

Unlike the North Santiam dataset, it looks like releases were structured in such a way that there is limited multicollinearity in the dataset! The worst offender is origin, with a DF corrected GVIF of  1.58. This is barely above the value of 1.5 applied by the most conservative modelers, and well below the more typical cutoffs of 10 or 5. From the biplots, we can assume much of the VIF comes from collinearity between origin and release location, release group density, or all three combined. NORs are only released at two sites and HORs are released at 5. NORs are also released at lower densities than HORs. 

To check that this is the source of the multicollinearity, let's build a model without release group density and without release location. 

```{r}
beyond_opt_main <- glm.nb(tlf ~ poly(jday_c,2) + sex + poly(density, 2) + poly(sex_ratio_y_l,2) + poly(sex_ratio_rg_l,2) + origin, data = mm_data)
kable(vif(beyond_opt_main), caption = "Variance Inflation Factors for model without release location") %>% kable_classic(full_width = F, html_font = "Cambria" ) 

beyond_opt_main <- glm.nb(tlf ~ poly(jday_c,2) + sex  + poly(sex_ratio_y_l,2) + poly(sex_ratio_rg_l,2)  + origin + release, data = mm_data)
kable(vif(beyond_opt_main), caption = "Variance Inflation Factors for model without release group density") %>% kable_classic(full_width = F, html_font = "Cambria" ) 
```

Yes, removing either release group density or release location reduces GVIFs.

## Distribution  

We have assumed so far that the negative binomial is the correct distribution to model fitness. This follows previous work by our lab and even major review papers, so it is clear negative binomial is superior to poisson and quasipoisson. However, there are extensions to negative binomial to deal with zero-inflation including ZINB and hurdle models and we should always check that a simpler model isn't better. 

We will fit fully saturated fixed effect model with interactions (no random effects) under poisson, quasipoisson, negbin, zero inflated negbin and hurdle negbin models, conduct a simple model selection procedure (only remove predictors that don't pass an LRT at p < 0.05) and compare fits of the optimized model.

### Poisson

Let's start with Poisson. 

```{r}
pois <- glm(tlf ~ poly(jday_c,2) + sex + poly(density, 2) + poly(sex_ratio_y_l,2) + poly(sex_ratio_rg_l,2) + origin + sex*origin + sex*poly(sex_ratio_y_l, 2)+ sex*poly(jday_c,2), data = mm_data, family = "poisson")
drop1(pois, test = "Chisq")
```

Dropping sex*density(non-linear) and refitting. 
```{r}
pois <- glm(tlf ~ poly(jday_c,2) + sex + poly(density, 2) + poly(sex_ratio_y_l,2) + poly(sex_ratio_rg_l,2) + origin + sex*origin + sex*poly(sex_ratio_y_l, 2) + sex*density, data = mm_data, family = "poisson")
drop1(pois, test = "Chisq")
```

Dropping sex*density and refitting. 

```{r}
pois <- glm(tlf ~ poly(jday_c,2) + sex + poly(density, 2) + poly(sex_ratio_y_l,2) + poly(sex_ratio_rg_l,2) + origin + sex*origin + sex*poly(sex_ratio_y_l, 2) , data = mm_data, family = "poisson")
drop1(pois, test = "Chisq")
```


Final Poisson model includes: Julian Day (Non-linear), Release Group Density (Non-Linear), Annual Sex Ratio (Non-Linear), Sex, Origin, and the interaction between Sex and Origin and Sex and Annual Sex Ratio.

Let's look at the model fit
```{r, message = FALSE, warning=FALSE}
summary(pois)
simulationOutput <- simulateResiduals(fittedModel = pois, plot = F)
plot(simulationOutput)
testZeroInflation(simulationOutput)
```

__Conclusion__   
Model fit under poisson is very poor. Overdispersed, zero-inflated and a strong relationship between residuals and predictors. The model is struggling between fitting all the zeros and fitting the tlf > 1. We should not expect reliable parameter estimates or p-values out of a Poisson fit. 

### NegBin

Let's see if estimating variance and mean separately (e.g. negative binomial) fixes the overdispersion.  

```{r}
glm_nb <- glm.nb(tlf ~ poly(jday_c,2) + sex + poly(density, 2) + poly(sex_ratio_y_l,2) + poly(sex_ratio_rg_l,2) + origin + sex*origin + sex*poly(sex_ratio_y_l, 2)+ sex*poly(jday_c,2), data = mm_data)
drop1(glm_nb, test = "Chisq")
```

Drop the sex* non-linear julian day interaction
```{r}
glm_nb <- glm.nb(tlf ~ poly(jday_c,2) + sex + poly(density, 2) + poly(sex_ratio_y_l,2) + poly(sex_ratio_rg_l,2)+ origin + sex*origin + sex*poly(sex_ratio_y_l, 2)+ sex*jday_c, data = mm_data)
drop1(glm_nb, test = "Chisq")
```
Drop the sex*  julian day interaction
```{r}
glm_nb <- glm.nb(tlf ~ poly(jday_c,2) + sex + poly(density, 2) + poly(sex_ratio_y_l,2) + poly(sex_ratio_rg_l,2) +  origin + sex*origin + sex*poly(sex_ratio_y_l, 2), data = mm_data)
drop1(glm_nb, test = "Chisq")
```

Drop sex*origin effect
```{r}
glm_nb <- glm.nb(tlf ~ poly(jday_c,2) + sex + poly(density, 2) + poly(sex_ratio_y_l,2) + poly(sex_ratio_rg_l,2) +  origin  + sex*poly(sex_ratio_y_l, 2), data = mm_data)
drop1(glm_nb, test = "Chisq")
```

Drop non-linear sex ratio of release group
```{r}
glm_nb <- glm.nb(tlf ~ poly(jday_c,2) + sex + poly(density, 2) + poly(sex_ratio_y_l,2) + sex_ratio_rg_l +  origin  + sex*poly(sex_ratio_y_l, 2), data = mm_data)
drop1(glm_nb, test = "Chisq")
```


Final model is sex, release day (non-linear), release group density and sex ratio, origin and the interaction between sex and annual sex ratio.

Let's evaluate model fit

```{r, message = FALSE, warning=FALSE}
summary(glm_nb)
simulationOutput <- simulateResiduals(fittedModel = glm_nb, plot = F)
plot(simulationOutput)
testZeroInflation(simulationOutput)
```

__Conclusion__  
This is a good fit to the data. We could probablit do even better with random effects, but this demosntrates at least that the negbin fixes the problems of the poisson. There is no evidence of any model fit problems, nor a zero inflation problem. However, let's look at zero-inflation models anyway.

### ZINB

Here we fit a zero inflated negative binomial. Here we model zero TLF and non-zero TLF separately. For the zero part of the model we do not include any predictors. We can't use the drop1 function to do model selection before, so we make (the rather big) assumption that model selection would have followed the same results as the negbin model and fit the final model after model selection using that distribution
```{r}
zinb <- zeroinfl(tlf ~ poly(jday_c,2) + sex + poly(density, 2) + poly(sex_ratio_y_l,2) + sex_ratio_rg_l +  origin  + sex*poly(sex_ratio_y_l, 2) | 1, data = mm_data, dist = "negbin" )
summary(zinb)
```

### Comparison
Let's compare models. First let's use a rootogram.

```{r}
rootogram(pois, main = "Poisson")
rootogram(glm_nb, main = "Negative Binomial")
rootogram(zinb, main = "Zero-Inflated Negative Binomial")
```


Now let's look at AIC and BIC
```{r}
AIC(pois, glm_nb, zinb)
BIC(pois, glm_nb, zinb)
```

Finally, let's conduct some likelihood ratio tests on nested models. 

```{r}
lmtest::lrtest(glm_nb, zinb )
```

### Conclusion  

The model fits above overwhelmingly support a Negative Binomial over the Zero-Inflated or Poisson models. The Poisson is a very poor fit to the data. Zero-inflated negative binomial and negative binomial provide equaivalently good fits, so we should choose the one with fewer parameters. 

## Model Selection

### Random Effects
Now lets fit the beyond optimal model. This has more fixed effects than we could possibly want in our final model, but that is desirable for finding the optimum random effect structure. We should also fit all fixed effects that could reasonably be non-linear using polynomials, as the linear model is nested within the polynomial and therefore the polynomial is better as the satured/beyond optimal.

```{r, cache = TRUE, eval = FALSE}
mm_beyond_opt <- glmmTMB(tlf ~ poly(jday_c,2) + sex + poly(density, 2) + poly(sex_ratio_y_l,2) + poly(sex_ratio_rg_l,2) + origin + release + sex*origin + sex*poly(sex_ratio_y_l, 2)+ sex*poly(jday_c,2) + (1|group) + (1|year), data = mm_data, family = nbinom2, REML = TRUE)

mm_beyond_opt2 <- glmmTMB(tlf ~ poly(jday_c,2) + sex + poly(density, 2) + poly(sex_ratio_y_l,2) + poly(sex_ratio_rg_l,2) + origin + release + sex*origin + sex*poly(sex_ratio_y_l, 2)+ sex*poly(jday_c,2) + (1|year), data = mm_data, family = nbinom2, REML = TRUE)

mm_beyond_opt3 <- glmmTMB(tlf ~ poly(jday_c,2) + sex + poly(density, 2) + poly(sex_ratio_y_l,2) + poly(sex_ratio_rg_l,2) + origin + release + sex*origin + sex*poly(sex_ratio_y_l, 2)+ sex*poly(jday_c,2) + (1|group) , data = mm_data, family = nbinom2, REML = TRUE)

mm_beyond_opt4 <- glmmTMB(tlf ~ poly(jday_c,2) + sex + poly(density, 2) + poly(sex_ratio_y_l,2) + poly(sex_ratio_rg_l,2) + origin + release + sex*origin + sex*poly(sex_ratio_y_l, 2)+ sex*poly(jday_c,2) , data = mm_data, family = nbinom2, REML = TRUE)



AIC(mm_beyond_opt, mm_beyond_opt2, mm_beyond_opt3, mm_beyond_opt4)
BIC(mm_beyond_opt, mm_beyond_opt2, mm_beyond_opt3, mm_beyond_opt4)

lmtest::lrtest(mm_beyond_opt4, mm_beyond_opt)
lmtest::lrtest(mm_beyond_opt4, mm_beyond_opt2)
lmtest::lrtest(mm_beyond_opt4, mm_beyond_opt3)
summary(mm_beyond_opt)
```

AIC and BIC and LRTs agree the best fit to the data is the full random effects model including both release group and year. 

Ultimately the correct random effects structure is a question about the inferences we'd like to make and AIC is only one piece of information to help us understand the releaitonship between parsimony and model fit. 

For example, so many of our variables are calculated at the level of release group, and including release group as a random effect means these variables will be competing with random intercepts for release group. Same goes for year. 

Since we are interested in evaluating the significance of predictors primarily, I'd prefer to be conservative and include them as random effectes. Failing to include year and release group as random effects implies that we are uninterested in the correlation within groups. Inferentially, this implies that the fixed effects at the level of release group or year (release group: sex ratio, density and year: n and sex ratio) are the only effects that might lead to correlation within the levels, and we freely pool across all levels of release group or year and attribute all variance to fixed effects.

We will include random effects for year and release group.



### Fixed Effects

Now let's turn to the otherside of the model and conduct model selection on the fixed effects.

We will conduct backwards stepwsie selection using Wald Tests and LRT, separately. 

#### Non-Linear Effects
We have a lot of potential non-linear effects. This will make a typical backwards stepwise model selection procedure very painful.

Let's fit a saturated model, with and without each non-linear effect and only retain the ones that improve the fit to the data according to LR tests and AIC.

Let's refit the model using ML and take our first look

```{r}
mm_beyond_opt <- glmmTMB(tlf ~ poly(jday_c,2) + sex + poly(density, 2) + poly(sex_ratio_y_l,2) + poly(sex_ratio_rg_l,2) + origin + release + sex*origin + sex*poly(sex_ratio_y_l, 2)+ sex*poly(jday_c,2) + (1|group) + (1|year), data = mm_data, family = nbinom2)

summary(mm_beyond_opt)
```

Now let's examine the of modeling effects of julian day, release group density, annual sex ratio and release group sex ratio as non-linear improves the model, in turn.

```{r}
mm_beyond_opt_lin <- glmmTMB(tlf ~ jday_c + sex + density + sex_ratio_y_l + sex_ratio_rg_l + origin + release + sex*origin + sex*sex_ratio_y_l+ sex*jday_c + (1|group) + (1|year), data = mm_data, family = nbinom2)

mm_beyond_opt_j <- glmmTMB(tlf ~ poly(jday_c,2) + sex + density + sex_ratio_y_l + sex_ratio_rg_l + origin + release + sex*origin + sex*sex_ratio_y_l+ sex*poly(jday_c,2) + (1|group) + (1|year), data = mm_data, family = nbinom2)

mm_beyond_opt_s <- glmmTMB(tlf ~ jday_c + sex + density + poly(sex_ratio_y_l,2) + sex_ratio_rg_l + origin + release + sex*origin + sex*poly(sex_ratio_y_l,2)+ sex*jday_c + (1|group) + (1|year), data = mm_data, family = nbinom2)

mm_beyond_opt_d <- glmmTMB(tlf ~ jday_c + sex + poly(density,2) + sex_ratio_y_l + sex_ratio_rg_l + origin + release + sex*origin + sex*sex_ratio_y_l+ sex*jday_c + (1|group) + (1|year), data = mm_data, family = nbinom2)

mm_beyond_opt_r <- glmmTMB(tlf ~ jday_c + sex + density + sex_ratio_y_l + poly(sex_ratio_rg_l,2) + origin + release + sex*origin + sex*sex_ratio_y_l+ sex*jday_c + (1|group) + (1|year), data = mm_data, family = nbinom2)

AIC(mm_beyond_opt, mm_beyond_opt_lin, mm_beyond_opt_j, mm_beyond_opt_s, mm_beyond_opt_d, mm_beyond_opt_r)
BIC(mm_beyond_opt, mm_beyond_opt_lin, mm_beyond_opt_j, mm_beyond_opt_s, mm_beyond_opt_d, mm_beyond_opt_r)
```

__Conclusion__
Only fitting density as non-linear improves the fit, and only marginally so. We will keep it and remove any non-linear effect using our standard model selection.

So our starting model for model selection is below

```{r}
mm_start <- glmmTMB(tlf ~ jday_c + sex + poly(density, 2) + sex_ratio_y_l + sex_ratio_rg_l + origin + release + sex*origin + sex*sex_ratio_y_l+ sex*jday_c + (1|group) + (1|year), data = mm_data, family = nbinom2)
summary(mm_start)
```

#### Wald Tests


First interaction to remove is sex*jday

```{r}
mm_wald <- glmmTMB(tlf ~ jday_c + sex + poly(density, 2) + sex_ratio_y_l + sex_ratio_rg_l + origin + release + sex*origin + sex*sex_ratio_y_l + (1|group) + (1|year), data = mm_data, family = nbinom2)

summary(mm_wald)
```

Next is sex ratio of release group

```{r}
mm_wald <- glmmTMB(tlf ~ jday_c + sex + poly(density, 2) + sex_ratio_y_l  + origin + release + sex*origin + sex*sex_ratio_y_l + (1|group) + (1|year), data = mm_data, family = nbinom2)

summary(mm_wald)
```

Next to remove is non-linear effect of density.
```{r}
mm_wald <- glmmTMB(tlf ~ jday_c + sex + density + sex_ratio_y_l  + origin + release + sex*origin + sex*sex_ratio_y_l + (1|group) + (1|year), data = mm_data, family = nbinom2)

summary(mm_wald)
```

Now density goes.

```{r}
mm_wald <- glmmTMB(tlf ~ jday_c + sex  + sex_ratio_y_l  + origin + release + sex*origin + sex*sex_ratio_y_l + (1|group) + (1|year), data = mm_data, family = nbinom2)

summary(mm_wald)
```

Final model according to Wald Tests includes Julian Day, Sex, Annual Sex Ratio, Release Location, Origin, Sex * Origin and Sex * Annual Sex Ratio

#### LRT

```{r}
mm_lrt <- glmmTMB(tlf ~ jday_c + sex + poly(density, 2) + sex_ratio_y_l + sex_ratio_rg_l + origin + release + sex*origin + sex*sex_ratio_y_l  + sex*jday_c+ (1|group) + (1|year), data = mm_data, family = nbinom2)
drop1(mm_lrt, test = "Chisq")
```

First to drop is the jday*sex interaction.

```{r}
mm_lrt <- glmmTMB(tlf ~ jday_c + sex + poly(density, 2) + sex_ratio_y_l + sex_ratio_rg_l + origin + release + sex*origin + sex*sex_ratio_y_l + (1|group) + (1|year), data = mm_data, family = nbinom2)
drop1(mm_lrt, test = "Chisq")
```


Then the release group sex ratio

```{r}
mm_lrt <- glmmTMB(tlf ~ jday_c + sex + poly(density, 2) + sex_ratio_y_l  + origin + release + sex*origin + sex*sex_ratio_y_l + (1|group) + (1|year), data = mm_data, family = nbinom2)
drop1(mm_lrt, test = "Chisq")
```

Then non-linear density effect. 

```{r}
mm_lrt <- glmmTMB(tlf ~ jday_c + sex + density + sex_ratio_y_l  + origin + release + sex*origin + sex*sex_ratio_y_l + (1|group) + (1|year), data = mm_data, family = nbinom2)
drop1(mm_lrt, test = "Chisq")
```

Now density

```{r}
mm_lrt <- glmmTMB(tlf ~ jday_c + sex +  sex_ratio_y_l  + origin + release + sex*origin + sex*sex_ratio_y_l + (1|group) + (1|year), data = mm_data, family = nbinom2)
drop1(mm_lrt, test = "Chisq")
```

Uh-oh something different. Now we remove release location effect.

```{r}
mm_lrt <- glmmTMB(tlf ~ jday_c + sex +  sex_ratio_y_l  + origin + sex*origin + sex*sex_ratio_y_l + (1|group) + (1|year), data = mm_data, family = nbinom2)
drop1(mm_lrt, test = "Chisq")
```

Done. Final model includes sex, annual sex ratio, release day, origin and two interactions sex* origin and sex * annual sex ratio

### Final Model

Stepwise selection according to Wald Test and likelihood ratio tests do not produce the same final model. Using likelihood ratio tests produces a sparse model that does not include the effect of release location compared to the Wald Test approach.

I think we should be more conservative here and use the final model from the LRT model selection procedure for a few reasons:  
(1) For this question (which predictors of fitness are significant), I'm inclined towards being conservative, generally.  
(2) There is moderate collinearity between origin and release location. Not enough to warrant excluding one or the other from the model selection procedure, but enough to elicit a small amount of concern.   
(3) Following up on 2 above, while there is not strong collinearity between origin and release location, this is because a small number HORs from Cougar got placed at otherwise only hatchery outplant HOR relerase locations (such as homestead). So, if we restrict ourselves to the NOR cougar and hatchery outplant HOR comparison, we likely would have set off some multicollinearity flags

Let's define our final model and collect the results

```{r}
final_model <- mm_lrt
kable(broom.mixed::tidy(final_model) %>% select(effect, group, term, estimate, std.error, p.value), caption =  "Final Model Fit", digits = 3) %>% kable_classic(font = "Arial")
```

## Model validation

Let's check on the fit.
```{r}
simulateResiduals(final_model, plot = TRUE)
```

Model fits excellently! The qq plot of simulated residuals shows a good fit, there is no evidence of overdispersion, and outliers don't seem to drive the fit. We also don't see any pattern to the residuals. 

## Effects

Here we interpret the model fit. 

There are three significant main effects, and two significant interactions. There are also two random effects.

__Main Effects__
There are 4 main effects in the final model, but one (sex) is not signficant and retained only because of it's interaction with origin and annual sex ratio. 

Interpreting the meaning of the fitted model parameters can be very challenging because of the link-function and the fact that multiple predictors are significant and interact. 
 
We use the effects package to translate the estimated parameters from the model into something we can actually understand. The approach here predicts the effect of different levels of a focal predictor, holding all others constant at a fixed values. 

These fixed values are determined differently for factor and numerical predictors. For numerical predictors (annual sex ratio and Julian Day of release), the fixed value is the simple mean. For factor predictors (sex and origin), we use a weighted average of the fitted values the levels of the factor, with weights proportional to the number of cases in each level.  

```{r, message = FALSE, warning=FALSE}
require(effects)
plot(predictorEffect("origin",final_model),
lines=list(multiline=TRUE), confint=list(style="bars"))
plot(predictorEffect("sex_ratio_y_l",final_model), lines=list(multiline=TRUE), confint=list(style="bars"))
plot(predictorEffect("jday_c",final_model))
```

__Origin:__ NOR salmon have substantially higher predicted fitness than HOR (Wald Test p = 0.000705) and this effect is somewhat stronger for males than females, but this interaction is only marginally significant and has a limited effect size (Wald Test = 0.0387). NOR males are predicted to be 2.1 fold more fit the HOR males, and NOR females are predicted to be 1.6 fold more fit than HOR females.  
__Sex Ratio:__ Overall, the annual sex ratio has a small effect on fitness, with male biased sex ratios producing somewhat higher fitness than females (Wald Test p = ), however this effect was much stronger for females than males (Wald Test p = ). Put in simple terms, changes in annual sex ratio affects fitness mostly through females, who perform worse when the sex ratio is female biased. Using the most extreme values in observed in any years (male:female ratio 0.6 and 2.0), female fitness is predicted to vary 3.5 fold, whereas male fitness is expected to vary 1.4 fold.  
__Release Day:__ Earlier releases are predicted to have greater fitness than later releases (Wald Test p value ). Individuals released on the earliest day are predicted to have 1.7 fold greater fitness than the latest release day.

__Random Effects__

The among year standard deviation in TLF was 0.5529 (log scale), and the among release group standard deviation was 0.2915 (log scale)


__Publication Plots__

Since the interaction is significant, let's plot and examine the effects of sex and sex ratio together.


```{r}


#let's not use the effect package plotting tools and just get the effects

#eff1 <- predictorEffect("sex_ratio_y_l", final_model, focal.levels = seq(-0.4,0.7,by = 0.1))
eff1 <- predictorEffect("sex_ratio_y_l", final_model)
effdf <- as.data.frame(eff1)

effdf %<>%
  mutate(sex_ratio = exp(sex_ratio_y_l))

actual_means <- mm_data %>%
  group_by(year, sex, sex_ratio_y) %>%
  summarise(mean_tlf = mean(tlf))

ggplot(data = effdf, aes(x = (sex_ratio), y = fit, color = sex))+ 
  geom_line()+scale_x_continuous(trans = "log", n.breaks = 10) +
  xlab( bquote(atop("Sex Ratio",(N[male]/N[female])))) +
  geom_smooth( aes(ymin = lower, ymax = upper, fill = sex, colour = sex), stat = "identity") +
  theme_bw()+ylab("TLF")+coord_cartesian(ylim = c(0, 1.25)) + scale_color_manual(labels = c("Female", "Male"), name = "Sex", values = c("#228833", "#AA3377")) + scale_fill_manual(labels = c("Female", "Male"), name = "Sex", values = c("#228833", "#AA3377")) +
  geom_rug(data = mm_data, aes(x = sex_ratio_y, y = NULL, color = NULL)) 

```

The plot above shows the predicted TLF (lines and 95% confidence intervals) from the final mixed model fit, and the mean TLF from the empirical data (triangles) against sex ratio in a given year for both male and female Chinook salmon outplanted or reintroduced above Cougar dam from 2007 to 2015. 


```{r}


#let's not use the effect package plotting tools and just get the effects

#eff1 <- predictorEffect("sex_ratio_y_l", final_model, focal.levels = seq(-0.4,0.7,by = 0.1))
eff1 <- predictorEffect("origin", final_model)
effdf <- as.data.frame(eff1)


ggplot(data = effdf, aes(x = (origin), y = fit, color = sex))+ 
  geom_point(position=position_dodge(width=0.3)) + 
  geom_errorbar(aes(ymin = lower, ymax = upper), position=position_dodge(width=0.3), width = 0.1)+scale_color_manual(labels = c("Female", "Male"), name = "Sex", values = c("#228833", "#AA3377"))+ylab("TLF")+xlab("Origin")+theme_bw()
  

```

```{r}


#let's not use the effect package plotting tools and just get the effects

#eff1 <- predictorEffect("sex_ratio_y_l", final_model, focal.levels = seq(-0.4,0.7,by = 0.1))
eff1 <- predictorEffect("jday_c", final_model)
effdf <- as.data.frame(eff1)

effdf %<>%
  mutate(jday = jday_c + 220)

actual_means <- mm_data %>%
  group_by(year, sex, sex_ratio_y) %>%
  summarise(mean_tlf = mean(tlf))

ggplot(data = effdf, aes(x = (jday), y = fit))+ 
  geom_line()+
  geom_smooth( aes(ymin = lower, ymax = upper), stat = "identity") +
  theme_bw()+
  xlab("Julian Day of Release")+ylab("TLF") 

```


# Other Analyses

This section of the notebook is dedicated to the numerous small questions and half-formed ideas that pop up during the work. It is much less well documented than the rest and is not intended to be shared widely.

## Double Transport

One dowsnide to the recycling/lsdr program is that NOR salmon descended from above the dam have to migrate through the south fork twice and be transported twice. Despite this NOR fitness is still greater than HOR fitness, but can we look into it in more detail. Is it possible for us to compare fitness of recycled individuals to individuals placed above the dam immediately? 

No, probably not without a lot of thought, whether or not a fish is recycled is confounded with so many other variables. For example we know later release dates reduce fitness. So do later release dates reduce fitness BECAUSE NOR fish are being released later due to LSDR/recycling? 

## Size effects

We have an estimate of size at maturity for about half (4321/8985) of our candidate parents. Our modeling tools are not compatible with missing data, so this would effectively cut our sample size in half. We chose not to fit it, but are examining it in a post hoc analysis in more detail here. 

Size at maturity is positively correlated with fitness in many salmonid species. Fitness differences between HOR and NOR salmon are partially mediated through lower size of HOR vs NOR adults returning to spawn, which is in turn driven by both growth rates and differences in age at maturity for NOR and HOR salmon.

In this analysis we ask several questions:

(1) Is size a significant predictor of fitness?  
(2) Do HOR and NOR salmon released above the dam vary in size?  
(3) Are these size differences driven by differences in AAM between NOR and HOR fish?  
(4) Can we parse the effects of size and origin? What is the best way to articulate the causal relationships between these variables and fitness? In other words do our data allow us to state things like "fitness differences between NOR and HOR candidate parents are driven by differences in size at maturity between HOR and NOR salmon"?

### Analysis

```{r, message=FALSE, warning = FALSE}
mm_data_size <-  parents %>%
  filter( year <2016) %>%
  select(date, sex, release, rkm, origin, year, type, length, tlf) %>%
  drop_na() %>%
  mutate(jday = as.numeric(format(date, "%j"))) %>% #julian day in this case: days since the first day of the year
  mutate(jday_c = scale(jday, scale = F), #center the julian day to help with convergence
         sex = as.factor(sex),
         release= as.factor(release),
         year = as.factor(year),
         group = as.factor(paste(date, release, type)))

# The dataset include 7438 individuals

# lets add density
dens <- mm_data_size %>%
 group_by(jday, release, year, type) %>%
  summarise(density = n())

mm_data_size %<>%
  left_join(dens)

# lets add overall size of release in a year
dens <- mm_data_size %>%
 group_by(year) %>%
  summarise(annual_n = n())

mm_data_size %<>%
  left_join(dens)


# lets add sex ratio
#build release group sex ratio variable
f <- mm_data_size %>% 
  filter(sex == "F") %>%
  group_by(release, jday, year, type) %>% 
  summarise(n_female_rg = n()) 

mm_data_size %<>%
  left_join(f)

m <- mm_data_size %>% 
  filter(sex == "M") %>%
  group_by(release, jday, year, type) %>% 
  summarise(n_male_rg = n()) 

mm_data_size %<>%
  left_join(m) %>%
  mutate(sex_ratio_rg = n_male_rg/n_female_rg)

# maybe the release groups all mix thoroughly spawn together and we should fit sex ratio at the level of year
f <- mm_data_size %>% 
  filter(sex == "F") %>%
  group_by( year) %>% 
  summarise(n_female_y = n()) 

mm_data_size %<>%
  left_join(f)

m <- mm_data_size %>% 
  filter(sex == "M") %>%
  group_by( year) %>% 
  summarise(n_male_y = n()) 

mm_data_size %<>%
  left_join(m) %>%
  mutate(sex_ratio_y = n_male_y/n_female_y)


mm_data_size %<>%
  mutate(sex_ratio_rg_l = log(sex_ratio_rg),
         sex_ratio_y_l = log(sex_ratio_y))

# there are a bunch of days where the only males or only females are released, this means we wind up with NAs when trying to log transform release group level variable, reducing sample size by 375 individuals. If we don't use that variable (release group sex ratio), then we can get rid of this dataset and use one with the full set of individuals, let's remember this

mm_data_size %<>%
  drop_na()

# oops forgot to convert origin to a factor
mm_data_size %<>%
  mutate(origin = as.factor(origin))

```

__Size effect__  

To assess the effect of size, we will compare the final model to a model with an additional effet of size and conduct LRT and Wald Tests

```{r}
size_glmm <- glmmTMB(tlf ~ jday_c + sex +  sex_ratio_y_l  + origin + sex*origin + sex*sex_ratio_y_l + length+ (1|group) + (1|year), data = mm_data_size, family = nbinom2)
null_size_glmm <-  glmmTMB(tlf ~ jday_c + sex +  sex_ratio_y_l  + origin + sex*origin + sex*sex_ratio_y_l +  (1|group) + (1|year), data = mm_data_size, family = nbinom2)

size_glmm2 <- glmmTMB(tlf ~ jday_c + sex +  sex_ratio_y_l  + origin + sex*origin + sex*sex_ratio_y_l + length*origin+ (1|group) + (1|year), data = mm_data_size, family = nbinom2)

AIC(size_glmm, null_size_glmm, size_glmm2)
BIC(size_glmm, null_size_glmm, size_glmm2)
anova(size_glmm, null_size_glmm, size_glmm2)
summary(size_glmm)

```

Yes, size is signficiantly predictive of TLF, but we already see the relationship with origin here. The origin effect is much reduced when also including size, suggesting correlation between these two predictors. There is no evidence of size*origin interaction.

Let's look more closely at the relationship between sex, size at maturity, and origin.

We'll make some summary plots and then fit a mixed model evaluating differences in length between sex and origin, using year as a random effect

```{r}
ggplot(data = mm_data_size) + geom_boxplot(aes(origin, length, color = sex))+theme_bw()

ggplot(data = mm_data_size) + geom_boxplot(aes(year, length, color = origin))+theme_bw()
mm_data_size %>%
  group_by(origin, sex) %>% 
  summarise(mean = mean(length), sd = sd(length))

mm_data_size %>%
  group_by(origin) %>% 
  summarise(mean = mean(length), sd = sd(length))

summary(lmer(length ~ origin + sex+ (1|year), data = mm_data_size))
drop1(lmer(length ~ origin + sex+ (1|year), data = mm_data_size), test = "Chisq")

```

NOR candidate parents are signficantly larger (beta = 2.92, se = 0.26, pvalue LRT < 2e-16), after controlling for the effect of sex and fitting year as a random effect. 

So we've established larger candidate parents produce more offspring, NOR candidate parents are significantly larger, and NOR candidate parents have higher fitness. Can we attempt to parse these effects? 

How much of the variation in fitness is due to origin alone and how much is due to size alone. Let's estimate partial coefficients of determination for origin and size. This is rarely reported in glmms, but to my understanding there is no reason why it is inappropriate (Stoffel et al 2021)

```{r}
# let's rescale some of the variable (fitting with lme4 which has a much harder time converging than glmmtmb)
#mm_data_size_scaled <- mm_data_size %>%
#  select(tlf, jday_c, sex, sex_ratio_y_l, origin,length, group, year) %>%
#  mutate(jday2 = jday_c/44,
#         length2 = length/10)



glmfit <- glm.nb(tlf ~ jday_c + sex +  sex_ratio_y_l  + origin + sex*origin + sex*sex_ratio_y_l + length+ group + year, data = mm_data_size_scaled)
glmfit <- glm.nb(tlf ~ jday_c + sex +  sex_ratio_y_l  + origin + sex*origin + sex*sex_ratio_y_l + length+ group + year, data = mm_data_size_scaled)

r2 <- rsq::rsq.partial(glmfit, adj = TRUE)
r2b <- rsq::rsq.glmm(lm4fit)
```

Okay, holding off on this for now because there is no straightforard implementation in R for glmmTMB, or any negbin glmm for that matter. It seems like it can be done according to Nakagawa 2017 (https://royalsocietypublishing.org/doi/10.1098/rsif.2017.0213). We "just" do commonality analysis on our model fit (https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.12166). The challenge is taking the time to parse the model object in R, and fitting conditioned models to calculate the partial R2s.  


### Conclusions

Larger candidate parents produce more offspring. NOR candidate parents are significantly larger. NOR candidate parents have higher fitness. Ultimately, we need to do some variance partitioning through commonality analysis to parse how much of the origin effect is mediated by the difference in size between NOR and HOR candidate parents. 



## F1s



```{r}

```


## Great-Grandparentage

This section is still mostly a dumping ground for code, needs to be documented and organized into something easily read by others.


__Comparing F2 to F1 Fitness__
note: take code chunk below and revise it to use the pedigree_meta, to keep track of parent and grandparent origin, also note that starting from pedigree means only offsping are included. probably best o use the code below to id f1s and f2s, the append these labels to the dedup dataset, along with fitness, after filtering to remove individuals that are not candidate parents
```{r}
grandparents <- pedigree %>%
  mutate(offspring_also_parent = case_when(offspring_sample_id %in% c(mother, father) ~ TRUE,
                                           TRUE ~ FALSE)) %>%
  left_join(select(dedup, sample_id, year), by = c("offspring_sample_id" = "sample_id"))


# F1s are individuals descended from known parents 
F1_list <- grandparents %>%
  filter(mother != "none" | father != "none") %>%
  pull(offspring_sample_id)

#F2s are individuals descended from F1s
F2_list <- grandparents %>%
  filter(mother %in% F1_list | father %in% F1_list) %>%
  pull(offspring_sample_id)
  
grandparents %<>%
   mutate(F1 = offspring_sample_id %in% F1_list,
          F2 = offspring_sample_id %in% F2_list) 

F2grandparent_list_dam <- grandparents %>% filter(F1 == TRUE, F2 == TRUE, offspring_also_parent == TRUE) %>% pull(mother)
F2grandparent_list_sire <- grandparents %>% filter(F1 == TRUE, F2 == TRUE, offspring_also_parent == TRUE) %>% pull(father)

grandparents %>% 
  filter(offspring_sample_id %in% F2grandparent_list_dam | offspring_sample_id %in% F2grandparent_list_sire )
  

kable(count(grandparents, F1, F2, offspring_also_parent) %>%
  rename(known_parents = F1, known_grandparents = F2, known_offspring = offspring_also_parent)) %>% kable_classic(full_width = F, html_font = "Cambria" ) 

# here we present the F2s broken down by return year. they need to return in 2015 or earlier for us to have a TLF
kable(grandparents %>% filter(F2 == TRUE) %>% count(year), caption = "F2 Sample Sizes, by return year") %>% kable_classic(full_width = F, html_font = "Cambria" ) 

# at some point we also need to subdivide these into those that descend from HORxHOR, HORxNOR and NORxNOR crosses. Ideally we would compare F0 fitness to F1 fitness to F2 fitness, but the F1s and F2s would all need to be NOR

f2s <- grandparents %>%
  left_join(parent_counts, by = c("offspring_sample_id" = "parent") ) %>%
  rename(fitness = n) %>%
  mutate(fitness = as.numeric(fitness),
         fitness = case_when(is.na(fitness) ~ 0,
                             TRUE ~ fitness)) %>%
  filter(F2 == TRUE, offspring_sample_id %in% parents$sample_id,  year < 2017)




f1s <- grandparents %>%
  left_join(parent_counts, by = c("offspring_sample_id" = "parent") ) %>%
  rename(fitness = n) %>%
  mutate(fitness = as.numeric(fitness),
         fitness = case_when(is.na(fitness) ~ 0,
                             TRUE ~ fitness)) %>%
  filter(F1 == TRUE, offspring_sample_id %in% parents$sample_id, year < 2017) 

a <- f2s %>% 
  group_by(year) %>%
  summarise(mean_fitness_f2 = mean(fitness), n_f2 = n())
  
b <- f1s %>% 
  group_by(year) %>%
  summarise(mean_fitness_f1 = mean(fitness), n_f1 = n())

f0s <- grandparents %>%
  left_join(parent_counts, by = c("offspring_sample_id" = "parent") ) %>%
  rename(fitness = n) %>%
  mutate(fitness = as.numeric(fitness),
         fitness = case_when(is.na(fitness) ~ 0,
                             TRUE ~ fitness)) %>%
  filter(F1 == FALSE, offspring_sample_id %in% parents$sample_id, year < 2017) # pretty sure this isnt working the right way

a <- f2s %>% 
  group_by(year) %>%
  summarise(mean_fitness_f2 = mean(fitness), n_f2 = n())
  
b <- f1s %>% 
  group_by(year) %>%
  summarise(mean_fitness_f1 = mean(fitness), n_f1 = n())

c <- f0s %>% 
  group_by(year) %>%
  summarise(mean_fitness_f0 = mean(fitness), n_f0 = n())

left_join(b, a) %>%
  left_join(c)

```

There are 3 years where we can compare TLF of F1s and F2s in our dataset, 2014, 2015 and 2016.

In 2014, there are only 3 F2s.
In 2015, the mean fitness of an F1 (ignoring parent origin, n = 123) was 0.31. The F2s (n = 28) had lower fitness, 0.28. 
In 2016, we only have years 3 and 4 offspring. F2s were way more fit than F1s, but this could have more to do with a change in AAM between F2s and F1s than any difference in TLF. We need 2021 retunrs to compare. 

__Conclusion__  
Not enough F2s with TLF to make a comparison.

